"""
This type stub file was generated by pyright.
"""

import numpy as np
import pandas.core.base as base
from pandas.core.base import IndexOpsMixin, PandasObject
from pandas.util._decorators import Appender, cache_readonly, deprecate_kwarg
from pandas.io.formats.printing import pprint_thing
from typing import Any, Optional

default_pprint = lambda x, max_seq_items = None: pprint_thing(x, escape_chars=('\t', '\r', '\n'), quote_strings=True, max_seq_items=max_seq_items)
__all__ = ['Index']
_unsortable_types = frozenset(('mixed', 'mixed-integer'))
_index_doc_kwargs = dict(klass='Index', inplace='', target_klass='Index', unique='Index', duplicated='np.ndarray')
_index_shared_docs = dict()
def _try_get_item(x):
    ...

class InvalidIndexError(Exception):
    ...


_o_dtype = np.dtype(object)
_Identity = object
def _new_Index(cls, d):
    """ This is called upon unpickling, rather than the default which doesn't
    have arguments and breaks __new__
    """
    ...

class Index(IndexOpsMixin, PandasObject):
    """
    Immutable ndarray implementing an ordered, sliceable set. The basic object
    storing axis labels for all pandas objects

    Parameters
    ----------
    data : array-like (1-dimensional)
    dtype : NumPy dtype (default: object)
    copy : bool
        Make a copy of input ndarray
    name : object
        Name to be stored in the index
    tupleize_cols : bool (default: True)
        When True, attempt to create a MultiIndex if possible

    Notes
    -----
    An Index instance can **only** contain hashable objects

    Examples
    --------
    >>> pd.Index([1, 2, 3])
    Int64Index([1, 2, 3], dtype='int64')

    >>> pd.Index(list('abc'))
    Index(['a', 'b', 'c'], dtype='object')

    See Also
    ---------
    RangeIndex : Index implementing a monotonic integer range
    CategoricalIndex : Index of :class:`Categorical` s.
    MultiIndex : A multi-level, or hierarchical, Index
    IntervalIndex : an Index of :class:`Interval` s.
    DatetimeIndex, TimedeltaIndex, PeriodIndex
    Int64Index, UInt64Index,  Float64Index
    """
    _join_precedence = ...
    _arrmap = ...
    _left_indexer_unique = ...
    _left_indexer = ...
    _inner_indexer = ...
    _outer_indexer = ...
    _box_scalars = ...
    _typ = ...
    _data = ...
    _id = ...
    name = ...
    asi8 = ...
    _comparables = ...
    _attributes = ...
    _allow_index_ops = ...
    _allow_datetime_index_ops = ...
    _allow_period_index_ops = ...
    _is_numeric_dtype = ...
    _can_hold_na = ...
    _defer_to_indexing = ...
    _infer_as_myclass = ...
    _engine_type = ...
    _accessors = ...
    str = ...
    def __new__(cls, data: Optional[Any] = ..., dtype: Optional[Any] = ..., copy: bool = ..., name: Optional[Any] = ..., fastpath: bool = ..., tupleize_cols: bool = ..., **kwargs):
        ...
    
    @classmethod
    def _simple_new(cls, values, name: Optional[Any] = ..., dtype: Optional[Any] = ..., **kwargs):
        """
        we require the we have a dtype compat for the values
        if we are passed a non-dtype compat, then coerce using the constructor

        Must be careful not to recurse.
        """
        ...
    
    @Appender(_index_shared_docs['_shallow_copy'])
    def _shallow_copy(self, values: Optional[Any] = ..., **kwargs):
        ...
    
    def _shallow_copy_with_infer(self, values: Optional[Any] = ..., **kwargs):
        """
        create a new Index inferring the class with passed value, don't copy
        the data, use the same object attributes with passed in attributes
        taking precedence

        *this is an internal non-public method*

        Parameters
        ----------
        values : the values to create the new Index, optional
        kwargs : updates the default attributes for this Index
        """
        ...
    
    def _deepcopy_if_needed(self, orig, copy: bool = ...):
        """
        .. versionadded:: 0.19.0

        Make a copy of self if data coincides (in memory) with orig.
        Subclasses should override this if self._base is not an ndarray.

        Parameters
        ----------
        orig : ndarray
            other ndarray to compare self._data against
        copy : boolean, default False
            when False, do not run any check, just return self

        Returns
        -------
        A copy of self if needed, otherwise self : Index
        """
        ...
    
    def _update_inplace(self, result, **kwargs):
        ...
    
    def _sort_levels_monotonic(self):
        """ compat with MultiIndex """
        ...
    
    @Appender(_index_shared_docs['_get_grouper_for_level'])
    def _get_grouper_for_level(self, mapper, level: Optional[Any] = ...):
        ...
    
    def is_(self, other):
        """
        More flexible, faster check like ``is`` but that works through views

        Note: this is *not* the same as ``Index.identical()``, which checks
        that metadata is also the same.

        Parameters
        ----------
        other : object
            other object to compare against.

        Returns
        -------
        True if both have same underlying data, False otherwise : bool
        """
        ...
    
    def _reset_identity(self):
        """Initializes or resets ``_id`` attribute with new object"""
        ...
    
    def __len__(self):
        """
        return the length of the Index
        """
        ...
    
    def __array__(self, dtype: Optional[Any] = ...):
        """ the array interface, return my values """
        ...
    
    def __array_wrap__(self, result, context: Optional[Any] = ...):
        """
        Gets called after a ufunc
        """
        ...
    
    @cache_readonly
    def dtype(self):
        """ return the dtype object of the underlying data """
        ...
    
    @cache_readonly
    def dtype_str(self):
        """ return the dtype str of the underlying data """
        ...
    
    @property
    def values(self):
        """ return the underlying data as an ndarray """
        ...
    
    def get_values(self):
        """ return the underlying data as an ndarray """
        ...
    
    @Appender(IndexOpsMixin.memory_usage.__doc__)
    def memory_usage(self, deep: bool = ...):
        ...
    
    @deprecate_kwarg(old_arg_name='n', new_arg_name='repeats')
    def repeat(self, repeats, *args, **kwargs):
        """
        Repeat elements of an Index. Refer to `numpy.ndarray.repeat`
        for more information about the `repeats` argument.

        See also
        --------
        numpy.ndarray.repeat
        """
        ...
    
    @Appender(_index_shared_docs['where'])
    def where(self, cond, other: Optional[Any] = ...):
        ...
    
    def ravel(self, order=...):
        """
        return an ndarray of the flattened values of the underlying data

        See also
        --------
        numpy.ndarray.ravel
        """
        ...
    
    @classmethod
    def _try_convert_to_int_index(cls, data, copy, name):
        """
        Attempt to convert an array of data into an integer index.

        Parameters
        ----------
        data : The data to convert.
        copy : Whether to copy the data or not.
        name : The name of the index returned.

        Returns
        -------
        int_index : data converted to either an Int64Index or a
                    UInt64Index

        Raises
        ------
        ValueError if the conversion was not successful.
        """
        ...
    
    @classmethod
    def _scalar_data_error(cls, data):
        ...
    
    @classmethod
    def _string_data_error(cls, data):
        ...
    
    @classmethod
    def _coerce_to_ndarray(cls, data):
        """coerces data to ndarray, raises on scalar data. Converts other
        iterables to list first and then to array. Does not touch ndarrays.
        """
        ...
    
    def _get_attributes_dict(self):
        """ return an attributes dict for my class """
        ...
    
    def view(self, cls: Optional[Any] = ...):
        ...
    
    def _coerce_scalar_to_index(self, item):
        """
        we need to coerce a scalar to a compat for our index type

        Parameters
        ----------
        item : scalar item to coerce
        """
        ...
    
    @Appender(_index_shared_docs['copy'])
    def copy(self, name: Optional[Any] = ..., deep: bool = ..., dtype: Optional[Any] = ..., **kwargs):
        ...
    
    def __copy__(self, **kwargs):
        ...
    
    def __deepcopy__(self, memo: Optional[Any] = ...):
        ...
    
    def _validate_names(self, name: Optional[Any] = ..., names: Optional[Any] = ..., deep: bool = ...):
        """
        Handles the quirks of having a singular 'name' parameter for general
        Index and plural 'names' parameter for MultiIndex.
        """
        ...
    
    def __unicode__(self):
        """
        Return a string representation for this object.

        Invoked by unicode(df) in py2 only. Yields a Unicode String in both
        py2/py3.
        """
        ...
    
    def _format_space(self):
        ...
    
    @property
    def _formatter_func(self):
        """
        Return the formatted data as a unicode string
        """
        ...
    
    def _format_data(self, name: Optional[Any] = ...):
        """
        Return the formatted data as a unicode string
        """
        ...
    
    def _format_attrs(self):
        """
        Return a list of tuples of the (attr,formatted_value)
        """
        ...
    
    def to_series(self, **kwargs):
        """
        Create a Series with both index and values equal to the index keys
        useful with map for returning an indexer based on an index

        Returns
        -------
        Series : dtype will be based on the type of the Index values.
        """
        ...
    
    def to_frame(self, index: bool = ...):
        """
        Create a DataFrame with a column containing the Index.

        .. versionadded:: 0.21.0

        Parameters
        ----------
        index : boolean, default True
            Set the index of the returned DataFrame as the original Index.

        Returns
        -------
        DataFrame : a DataFrame containing the original Index data.
        """
        ...
    
    def _to_embed(self, keep_tz: bool = ...):
        """
        *this is an internal non-public method*

        return an array repr of this object, potentially casting to object

        """
        ...
    
    @Appender(_index_shared_docs['astype'])
    def astype(self, dtype, copy: bool = ...):
        ...
    
    def _to_safe_for_reshape(self):
        """ convert to object if we are a categorical """
        ...
    
    def to_datetime(self, dayfirst: bool = ...):
        """
        DEPRECATED: use :meth:`pandas.to_datetime` instead.

        For an Index containing strings or datetime.datetime objects, attempt
        conversion to DatetimeIndex
        """
        ...
    
    def _assert_can_do_setop(self, other):
        ...
    
    def _convert_can_do_setop(self, other):
        ...
    
    def _convert_for_op(self, value):
        """ Convert value to be insertable to ndarray """
        ...
    
    def _assert_can_do_op(self, value):
        """ Check value is valid for scalar op """
        ...
    
    @property
    def nlevels(self):
        ...
    
    def _get_names(self):
        ...
    
    def _set_names(self, values, level: Optional[Any] = ...):
        self.name = ...
    
    names = ...
    def set_names(self, names, level: Optional[Any] = ..., inplace: bool = ...):
        """
        Set new names on index. Defaults to returning new index.

        Parameters
        ----------
        names : str or sequence
            name(s) to set
        level : int, level name, or sequence of int/level names (default None)
            If the index is a MultiIndex (hierarchical), level(s) to set (None
            for all levels).  Otherwise level must be None
        inplace : bool
            if True, mutates in place

        Returns
        -------
        new index (of same type and class...etc) [if inplace, returns None]

        Examples
        --------
        >>> Index([1, 2, 3, 4]).set_names('foo')
        Int64Index([1, 2, 3, 4], dtype='int64')
        >>> Index([1, 2, 3, 4]).set_names(['foo'])
        Int64Index([1, 2, 3, 4], dtype='int64')
        >>> idx = MultiIndex.from_tuples([(1, u'one'), (1, u'two'),
                                          (2, u'one'), (2, u'two')],
                                          names=['foo', 'bar'])
        >>> idx.set_names(['baz', 'quz'])
        MultiIndex(levels=[[1, 2], [u'one', u'two']],
                   labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
                   names=[u'baz', u'quz'])
        >>> idx.set_names('baz', level=0)
        MultiIndex(levels=[[1, 2], [u'one', u'two']],
                   labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
                   names=[u'baz', u'bar'])
        """
        ...
    
    def rename(self, name, inplace: bool = ...):
        """
        Set new names on index. Defaults to returning new index.

        Parameters
        ----------
        name : str or list
            name to set
        inplace : bool
            if True, mutates in place

        Returns
        -------
        new index (of same type and class...etc) [if inplace, returns None]
        """
        ...
    
    def reshape(self, *args, **kwargs):
        """
        NOT IMPLEMENTED: do not call this method, as reshaping is not
        supported for Index objects and will raise an error.

        Reshape an Index.
        """
        ...
    
    @property
    def _has_complex_internals(self):
        ...
    
    def summary(self, name: Optional[Any] = ...):
        ...
    
    def _mpl_repr(self):
        ...
    
    _na_value = ...
    @property
    def is_monotonic(self):
        """ alias for is_monotonic_increasing (deprecated) """
        ...
    
    @property
    def is_monotonic_increasing(self):
        """
        return if the index is monotonic increasing (only equal or
        increasing) values.

        Examples
        --------
        >>> Index([1, 2, 3]).is_monotonic_increasing
        True
        >>> Index([1, 2, 2]).is_monotonic_increasing
        True
        >>> Index([1, 3, 2]).is_monotonic_increasing
        False
        """
        ...
    
    @property
    def is_monotonic_decreasing(self):
        """
        return if the index is monotonic decreasing (only equal or
        decreasing) values.

        Examples
        --------
        >>> Index([3, 2, 1]).is_monotonic_decreasing
        True
        >>> Index([3, 2, 2]).is_monotonic_decreasing
        True
        >>> Index([3, 1, 2]).is_monotonic_decreasing
        False
        """
        ...
    
    @property
    def _is_strictly_monotonic_increasing(self):
        """return if the index is strictly monotonic increasing
        (only increasing) values

        Examples
        --------
        >>> Index([1, 2, 3])._is_strictly_monotonic_increasing
        True
        >>> Index([1, 2, 2])._is_strictly_monotonic_increasing
        False
        >>> Index([1, 3, 2])._is_strictly_monotonic_increasing
        False
        """
        ...
    
    @property
    def _is_strictly_monotonic_decreasing(self):
        """return if the index is strictly monotonic decreasing
        (only decreasing) values

        Examples
        --------
        >>> Index([3, 2, 1])._is_strictly_monotonic_decreasing
        True
        >>> Index([3, 2, 2])._is_strictly_monotonic_decreasing
        False
        >>> Index([3, 1, 2])._is_strictly_monotonic_decreasing
        False
        """
        ...
    
    def is_lexsorted_for_tuple(self, tup):
        ...
    
    @cache_readonly(allow_setting=True)
    def is_unique(self):
        """ return if the index has unique values """
        ...
    
    @property
    def has_duplicates(self):
        ...
    
    def is_boolean(self):
        ...
    
    def is_integer(self):
        ...
    
    def is_floating(self):
        ...
    
    def is_numeric(self):
        ...
    
    def is_object(self):
        ...
    
    def is_categorical(self):
        ...
    
    def is_interval(self):
        ...
    
    def is_mixed(self):
        ...
    
    def holds_integer(self):
        ...
    
    @Appender(_index_shared_docs['_convert_scalar_indexer'])
    def _convert_scalar_indexer(self, key, kind: Optional[Any] = ...):
        ...
    
    @Appender(_index_shared_docs['_convert_slice_indexer'])
    def _convert_slice_indexer(self, key, kind: Optional[Any] = ...):
        ...
    
    def _convert_listlike_indexer(self, keyarr, kind: Optional[Any] = ...):
        """
        Parameters
        ----------
        keyarr : list-like
            Indexer to convert.

        Returns
        -------
        tuple (indexer, keyarr)
            indexer is an ndarray or None if cannot convert
            keyarr are tuple-safe keys
        """
        ...
    
    @Appender(_index_shared_docs['_convert_arr_indexer'])
    def _convert_arr_indexer(self, keyarr):
        ...
    
    @Appender(_index_shared_docs['_convert_index_indexer'])
    def _convert_index_indexer(self, keyarr):
        ...
    
    @Appender(_index_shared_docs['_convert_list_indexer'])
    def _convert_list_indexer(self, keyarr, kind: Optional[Any] = ...):
        ...
    
    def _invalid_indexer(self, form, key):
        """ consistent invalid indexer message """
        ...
    
    def get_duplicates(self):
        ...
    
    _get_duplicates = ...
    def _cleanup(self):
        ...
    
    @cache_readonly
    def _constructor(self):
        ...
    
    @cache_readonly
    def _engine(self):
        ...
    
    def _validate_index_level(self, level):
        """
        Validate index level.

        For single-level Index getting level number is a no-op, but some
        verification must be done like in MultiIndex.

        """
        ...
    
    def _get_level_number(self, level):
        ...
    
    @cache_readonly
    def inferred_type(self):
        """ return a string of the type inferred from the values """
        ...
    
    def _is_memory_usage_qualified(self):
        """ return a boolean if we need a qualified .info display """
        ...
    
    def is_type_compatible(self, kind):
        ...
    
    @cache_readonly
    def is_all_dates(self):
        ...
    
    def __reduce__(self):
        ...
    
    def __setstate__(self, state):
        """Necessary for making this object picklable"""
        ...
    
    _unpickle_compat = ...
    def __nonzero__(self):
        ...
    
    __bool__ = ...
    @Appender(_index_shared_docs['__contains__'] % _index_doc_kwargs)
    def __contains__(self, key):
        ...
    
    @Appender(_index_shared_docs['contains'] % _index_doc_kwargs)
    def contains(self, key):
        ...
    
    def __hash__(self):
        ...
    
    def __setitem__(self, key, value):
        ...
    
    def __getitem__(self, key):
        """
        Override numpy.ndarray's __getitem__ method to work as desired.

        This function adds lists and Series as valid boolean indexers
        (ndarrays only supports ndarray with dtype=bool).

        If resulting ndim != 1, plain ndarray is returned instead of
        corresponding `Index` subclass.

        """
        ...
    
    def append(self, other):
        """
        Append a collection of Index options together

        Parameters
        ----------
        other : Index or list/tuple of indices

        Returns
        -------
        appended : Index
        """
        ...
    
    def _concat(self, to_concat, name):
        ...
    
    def _concat_same_dtype(self, to_concat, name):
        """
        Concatenate to_concat which has the same class
        """
        ...
    
    @Appender(_index_shared_docs['take'] % _index_doc_kwargs)
    def take(self, indices, axis=..., allow_fill: bool = ..., fill_value: Optional[Any] = ..., **kwargs):
        ...
    
    def _assert_take_fillable(self, values, indices, allow_fill: bool = ..., fill_value: Optional[Any] = ..., na_value=...):
        """ Internal method to handle NA filling of take """
        ...
    
    @cache_readonly
    def _isnan(self):
        """ return if each value is nan"""
        ...
    
    @cache_readonly
    def _nan_idxs(self):
        ...
    
    @cache_readonly
    def hasnans(self):
        """ return if I have any nans; enables various perf speedups """
        ...
    
    def isna(self):
        """
        Detect missing values

        .. versionadded:: 0.20.0

        Returns
        -------
        a boolean array of whether my values are NA

        See also
        --------
        isnull : alias of isna
        pandas.isna : top-level isna
        """
        ...
    
    isnull = ...
    def notna(self):
        """
        Inverse of isna

        .. versionadded:: 0.20.0

        Returns
        -------
        a boolean array of whether my values are not NA

        See also
        --------
        notnull : alias of notna
        pandas.notna : top-level notna
        """
        ...
    
    notnull = ...
    def putmask(self, mask, value):
        """
        return a new Index of the values set with the mask

        See also
        --------
        numpy.ndarray.putmask
        """
        ...
    
    def format(self, name: bool = ..., formatter: Optional[Any] = ..., **kwargs):
        """
        Render a string representation of the Index
        """
        ...
    
    def _format_with_header(self, header, na_rep=..., **kwargs):
        ...
    
    def to_native_types(self, slicer: Optional[Any] = ..., **kwargs):
        """
        Format specified values of `self` and return them.

        Parameters
        ----------
        slicer : int, array-like
            An indexer into `self` that specifies which values
            are used in the formatting process.
        kwargs : dict
            Options for specifying how the values should be formatted.
            These options include the following:

            1) na_rep : str
                The value that serves as a placeholder for NULL values
            2) quoting : bool or None
                Whether or not there are quoted values in `self`
            3) date_format : str
                The format used to represent date-like values
        """
        ...
    
    def _format_native_types(self, na_rep=..., quoting: Optional[Any] = ..., **kwargs):
        """ actually format my specific types """
        ...
    
    def equals(self, other):
        """
        Determines if two Index objects contain the same elements.
        """
        ...
    
    def identical(self, other):
        """Similar to equals, but check that other comparable attributes are
        also equal
        """
        ...
    
    def asof(self, label):
        """
        For a sorted index, return the most recent label up to and including
        the passed label. Return NaN if not found.

        See also
        --------
        get_loc : asof is a thin wrapper around get_loc with method='pad'
        """
        ...
    
    def asof_locs(self, where, mask):
        """
        where : array of timestamps
        mask : array of booleans where data is not NA

        """
        ...
    
    def sort_values(self, return_indexer: bool = ..., ascending: bool = ...):
        """
        Return sorted copy of Index
        """
        ...
    
    def sort(self, *args, **kwargs):
        ...
    
    def sortlevel(self, level: Optional[Any] = ..., ascending: bool = ..., sort_remaining: Optional[Any] = ...):
        """

        For internal compatibility with with the Index API

        Sort the Index. This is for compat with MultiIndex

        Parameters
        ----------
        ascending : boolean, default True
            False to sort in descending order

        level, sort_remaining are compat parameters

        Returns
        -------
        sorted_index : Index
        """
        ...
    
    def shift(self, periods=..., freq: Optional[Any] = ...):
        """
        Shift Index containing datetime objects by input number of periods and
        DateOffset

        Returns
        -------
        shifted : Index
        """
        ...
    
    def argsort(self, *args, **kwargs):
        """
        Returns the indices that would sort the index and its
        underlying data.

        Returns
        -------
        argsorted : numpy array

        See also
        --------
        numpy.ndarray.argsort
        """
        ...
    
    def __add__(self, other):
        ...
    
    def __radd__(self, other):
        ...
    
    __iadd__ = ...
    def __sub__(self, other):
        ...
    
    def __and__(self, other):
        ...
    
    def __or__(self, other):
        ...
    
    def __xor__(self, other):
        ...
    
    def _get_consensus_name(self, other):
        """
        Given 2 indexes, give a consensus name meaning
        we take the not None one, or None if the names differ.
        Return a new object if we are resetting the name
        """
        ...
    
    def union(self, other):
        """
        Form the union of two Index objects and sorts if possible.

        Parameters
        ----------
        other : Index or array-like

        Returns
        -------
        union : Index

        Examples
        --------

        >>> idx1 = pd.Index([1, 2, 3, 4])
        >>> idx2 = pd.Index([3, 4, 5, 6])
        >>> idx1.union(idx2)
        Int64Index([1, 2, 3, 4, 5, 6], dtype='int64')

        """
        ...
    
    def _wrap_union_result(self, other, result):
        ...
    
    def intersection(self, other):
        """
        Form the intersection of two Index objects.

        This returns a new Index with elements common to the index and `other`,
        preserving the order of the calling index.

        Parameters
        ----------
        other : Index or array-like

        Returns
        -------
        intersection : Index

        Examples
        --------

        >>> idx1 = pd.Index([1, 2, 3, 4])
        >>> idx2 = pd.Index([3, 4, 5, 6])
        >>> idx1.intersection(idx2)
        Int64Index([3, 4], dtype='int64')

        """
        ...
    
    def difference(self, other):
        """
        Return a new Index with elements from the index that are not in
        `other`.

        This is the set difference of two Index objects.
        It's sorted if sorting is possible.

        Parameters
        ----------
        other : Index or array-like

        Returns
        -------
        difference : Index

        Examples
        --------

        >>> idx1 = pd.Index([1, 2, 3, 4])
        >>> idx2 = pd.Index([3, 4, 5, 6])
        >>> idx1.difference(idx2)
        Int64Index([1, 2], dtype='int64')

        """
        ...
    
    def symmetric_difference(self, other, result_name: Optional[Any] = ...):
        """
        Compute the symmetric difference of two Index objects.
        It's sorted if sorting is possible.

        Parameters
        ----------
        other : Index or array-like
        result_name : str

        Returns
        -------
        symmetric_difference : Index

        Notes
        -----
        ``symmetric_difference`` contains elements that appear in either
        ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by
        ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates
        dropped.

        Examples
        --------
        >>> idx1 = Index([1, 2, 3, 4])
        >>> idx2 = Index([2, 3, 4, 5])
        >>> idx1.symmetric_difference(idx2)
        Int64Index([1, 5], dtype='int64')

        You can also use the ``^`` operator:

        >>> idx1 ^ idx2
        Int64Index([1, 5], dtype='int64')
        """
        ...
    
    def _get_unique_index(self, dropna: bool = ...):
        """
        Returns an index containing unique values.

        Parameters
        ----------
        dropna : bool
            If True, NaN values are dropped.

        Returns
        -------
        uniques : index
        """
        ...
    
    @Appender(_index_shared_docs['get_loc'])
    def get_loc(self, key, method: Optional[Any] = ..., tolerance: Optional[Any] = ...):
        ...
    
    def get_value(self, series, key):
        """
        Fast lookup of value from 1-dimensional ndarray. Only use this if you
        know what you're doing
        """
        ...
    
    def set_value(self, arr, key, value):
        """
        Fast lookup of value from 1-dimensional ndarray. Only use this if you
        know what you're doing
        """
        ...
    
    def _get_level_values(self, level):
        """
        Return an Index of values for requested level, equal to the length
        of the index.

        Parameters
        ----------
        level : int or str
            ``level`` is either the integer position of the level in the
            MultiIndex, or the name of the level.

        Returns
        -------
        values : Index
            ``self``, as there is only one level in the Index.

        See also
        ---------
        pandas.MultiIndex.get_level_values : get values for a level of a
                                             MultiIndex
        """
        ...
    
    get_level_values = ...
    @Appender(_index_shared_docs['get_indexer'] % _index_doc_kwargs)
    def get_indexer(self, target, method: Optional[Any] = ..., limit: Optional[Any] = ..., tolerance: Optional[Any] = ...):
        ...
    
    def _convert_tolerance(self, tolerance, target):
        ...
    
    def _get_fill_indexer(self, target, method, limit: Optional[Any] = ..., tolerance: Optional[Any] = ...):
        ...
    
    def _get_fill_indexer_searchsorted(self, target, method, limit: Optional[Any] = ...):
        """
        Fallback pad/backfill get_indexer that works for monotonic decreasing
        indexes and non-monotonic targets
        """
        ...
    
    def _get_nearest_indexer(self, target, limit, tolerance):
        """
        Get the indexer for the nearest index labels; requires an index with
        values that can be subtracted from each other (e.g., not strings or
        tuples).
        """
        ...
    
    def _filter_indexer_tolerance(self, target, indexer, tolerance):
        ...
    
    @Appender(_index_shared_docs['get_indexer_non_unique'] % _index_doc_kwargs)
    def get_indexer_non_unique(self, target):
        ...
    
    def get_indexer_for(self, target, **kwargs):
        """
        guaranteed return of an indexer even when non-unique
        This dispatches to get_indexer or get_indexer_nonunique as appropriate
        """
        ...
    
    def _maybe_promote(self, other):
        ...
    
    def groupby(self, values):
        """
        Group the index labels by a given array of values.

        Parameters
        ----------
        values : array
            Values used to determine the groups.

        Returns
        -------
        groups : dict
            {group name -> group labels}
        """
        ...
    
    def map(self, mapper):
        """Apply mapper function to an index.

        Parameters
        ----------
        mapper : callable
            Function to be applied.

        Returns
        -------
        applied : Union[Index, MultiIndex], inferred
            The output of the mapping function applied to the index.
            If the function returns a tuple with more than one element
            a MultiIndex will be returned.

        """
        ...
    
    def isin(self, values, level: Optional[Any] = ...):
        """
        Compute boolean array of whether each index value is found in the
        passed set of values.

        Parameters
        ----------
        values : set or list-like
            Sought values.

            .. versionadded:: 0.18.1

            Support for values as a set

        level : str or int, optional
            Name or position of the index level to use (if the index is a
            MultiIndex).

        Notes
        -----
        If `level` is specified:

        - if it is the name of one *and only one* index level, use that level;
        - otherwise it should be a number indicating level position.

        Returns
        -------
        is_contained : ndarray (boolean dtype)

        """
        ...
    
    def _can_reindex(self, indexer):
        """
        *this is an internal non-public method*

        Check if we are allowing reindexing with this particular indexer

        Parameters
        ----------
        indexer : an integer indexer

        Raises
        ------
        ValueError if its a duplicate axis
        """
        ...
    
    def reindex(self, target, method: Optional[Any] = ..., level: Optional[Any] = ..., limit: Optional[Any] = ..., tolerance: Optional[Any] = ...):
        """
        Create index with target's values (move/add/delete values as necessary)

        Parameters
        ----------
        target : an iterable

        Returns
        -------
        new_index : pd.Index
            Resulting index
        indexer : np.ndarray or None
            Indices of output values in original index

        """
        ...
    
    def _reindex_non_unique(self, target):
        """
        *this is an internal non-public method*

        Create a new index with target's values (move/add/delete values as
        necessary) use with non-unique Index and a possibly non-unique target

        Parameters
        ----------
        target : an iterable

        Returns
        -------
        new_index : pd.Index
            Resulting index
        indexer : np.ndarray or None
            Indices of output values in original index

        """
        ...
    
    @Appender(_index_shared_docs['join'])
    def join(self, other, how=..., level: Optional[Any] = ..., return_indexers: bool = ..., sort: bool = ...):
        ...
    
    def _join_multi(self, other, how, return_indexers: bool = ...):
        ...
    
    def _join_non_unique(self, other, how=..., return_indexers: bool = ...):
        ...
    
    def _join_level(self, other, level, how=..., return_indexers: bool = ..., keep_order: bool = ...):
        """
        The join method *only* affects the level of the resulting
        MultiIndex. Otherwise it just exactly aligns the Index data to the
        labels of the level in the MultiIndex. If `keep_order` == True, the
        order of the data indexed by the MultiIndex will not be changed;
        otherwise, it will tie out with `other`.
        """
        ...
    
    def _join_monotonic(self, other, how=..., return_indexers: bool = ...):
        ...
    
    def _wrap_joined_index(self, joined, other):
        ...
    
    def _get_string_slice(self, key, use_lhs: bool = ..., use_rhs: bool = ...):
        ...
    
    def slice_indexer(self, start: Optional[Any] = ..., end: Optional[Any] = ..., step: Optional[Any] = ..., kind: Optional[Any] = ...):
        """
        For an ordered Index, compute the slice indexer for input labels and
        step

        Parameters
        ----------
        start : label, default None
            If None, defaults to the beginning
        end : label, default None
            If None, defaults to the end
        step : int, default None
        kind : string, default None

        Returns
        -------
        indexer : ndarray or slice

        Notes
        -----
        This function assumes that the data is sorted, so use at your own peril
        """
        ...
    
    def _maybe_cast_indexer(self, key):
        """
        If we have a float key and are not a floating index
        then try to cast to an int if equivalent
        """
        ...
    
    def _validate_indexer(self, form, key, kind):
        """
        if we are positional indexer
        validate that we have appropriate typed bounds
        must be an integer
        """
        ...
    
    @Appender(_index_shared_docs['_maybe_cast_slice_bound'])
    def _maybe_cast_slice_bound(self, label, side, kind):
        ...
    
    def _searchsorted_monotonic(self, label, side=...):
        ...
    
    def _get_loc_only_exact_matches(self, key):
        """
        This is overriden on subclasses (namely, IntervalIndex) to control
        get_slice_bound.
        """
        ...
    
    def get_slice_bound(self, label, side, kind):
        """
        Calculate slice bound that corresponds to given label.

        Returns leftmost (one-past-the-rightmost if ``side=='right'``) position
        of given label.

        Parameters
        ----------
        label : object
        side : {'left', 'right'}
        kind : {'ix', 'loc', 'getitem'}

        """
        ...
    
    def slice_locs(self, start: Optional[Any] = ..., end: Optional[Any] = ..., step: Optional[Any] = ..., kind: Optional[Any] = ...):
        """
        Compute slice locations for input labels.

        Parameters
        ----------
        start : label, default None
            If None, defaults to the beginning
        end : label, default None
            If None, defaults to the end
        step : int, defaults None
            If None, defaults to 1
        kind : {'ix', 'loc', 'getitem'} or None

        Returns
        -------
        start, end : int

        Notes
        -----
        This method only works if the index is monotonic or unique.

        Examples
        ---------
        >>> idx = pd.Index(list('abcd'))
        >>> idx.slice_locs(start='b', end='c')
        (1, 3)

        See Also
        --------
        Index.get_loc : Get location for a single label
        """
        ...
    
    def delete(self, loc):
        """
        Make new Index with passed location(-s) deleted

        Returns
        -------
        new_index : Index
        """
        ...
    
    def insert(self, loc, item):
        """
        Make new Index inserting new item at location. Follows
        Python list.append semantics for negative values

        Parameters
        ----------
        loc : int
        item : object

        Returns
        -------
        new_index : Index
        """
        ...
    
    def drop(self, labels, errors=...):
        """
        Make new Index with passed list of labels deleted

        Parameters
        ----------
        labels : array-like
        errors : {'ignore', 'raise'}, default 'raise'
            If 'ignore', suppress error and existing labels are dropped.

        Returns
        -------
        dropped : Index
        """
        ...
    
    @Appender(base._shared_docs['unique'] % _index_doc_kwargs)
    def unique(self):
        ...
    
    @Appender(base._shared_docs['drop_duplicates'] % _index_doc_kwargs)
    def drop_duplicates(self, keep=...):
        ...
    
    @Appender(base._shared_docs['duplicated'] % _index_doc_kwargs)
    def duplicated(self, keep=...):
        ...
    
    @Appender(_index_shared_docs['fillna'])
    def fillna(self, value: Optional[Any] = ..., downcast: Optional[Any] = ...):
        ...
    
    @Appender(_index_shared_docs['dropna'])
    def dropna(self, how=...):
        ...
    
    def _evaluate_with_timedelta_like(self, other, op, opstr):
        ...
    
    def _evaluate_with_datetime_like(self, other, op, opstr):
        ...
    
    def _evaluate_compare(self, op):
        ...
    
    @classmethod
    def _add_comparison_methods(cls):
        """ add in comparison methods """
        ...
    
    @classmethod
    def _add_numeric_methods_add_sub_disabled(cls):
        """ add in the numeric add/sub methods to disable """
        ...
    
    @classmethod
    def _add_numeric_methods_disabled(cls):
        """ add in numeric methods to disable other than add/sub """
        ...
    
    def _maybe_update_attributes(self, attrs):
        """ Update Index attributes (e.g. freq) depending on op """
        ...
    
    def _validate_for_numeric_unaryop(self, op, opstr):
        """ validate if we can perform a numeric unary operation """
        ...
    
    def _validate_for_numeric_binop(self, other, op, opstr):
        """
        return valid other, evaluate or raise TypeError
        if we are not of the appropriate type

        internal method called by ops
        """
        ...
    
    @classmethod
    def _add_numeric_methods_binary(cls):
        """ add in numeric methods """
        ...
    
    @classmethod
    def _add_numeric_methods_unary(cls):
        """ add in numeric unary methods """
        ...
    
    @classmethod
    def _add_numeric_methods(cls):
        ...
    
    @classmethod
    def _add_logical_methods(cls):
        """ add in logical methods """
        ...
    
    @classmethod
    def _add_logical_methods_disabled(cls):
        """ add in logical methods to disable """
        ...
    


def _ensure_index_from_sequences(sequences, names: Optional[Any] = ...):
    """Construct an index from sequences of data.

    A single sequence returns an Index. Many sequences returns a
    MultiIndex.

    Parameters
    ----------
    sequences : sequence of sequences
    names : sequence of str

    Returns
    -------
    index : Index or MultiIndex

    Examples
    --------
    >>> _ensure_index_from_sequences([[1, 2, 3]], names=['name'])
    Int64Index([1, 2, 3], dtype='int64', name='name')

    >>> _ensure_index_from_sequences([['a', 'a'], ['a', 'b']],
                                     names=['L1', 'L2'])
    MultiIndex(levels=[['a'], ['a', 'b']],
               labels=[[0, 0], [0, 1]],
               names=['L1', 'L2'])

    See Also
    --------
    _ensure_index
    """
    ...

def _ensure_index(index_like, copy: bool = ...):
    """
    Ensure that we have an index from some index-like object

    Parameters
    ----------
    index : sequence
        An Index or other sequence
    copy : bool

    Returns
    -------
    index : Index or MultiIndex

    Examples
    --------
    >>> _ensure_index(['a', 'b'])
    Index(['a', 'b'], dtype='object')

    >>> _ensure_index([('a', 'a'),  ('b', 'c')])
    Index([('a', 'a'), ('b', 'c')], dtype='object')

    >>> _ensure_index([['a', 'a'], ['b', 'c']])
    MultiIndex(levels=[['a'], ['b', 'c']],
               labels=[[0, 0], [0, 1]])

    See Also
    --------
    _ensure_index_from_sequences
    """
    ...

def _get_na_value(dtype):
    ...

def _ensure_has_len(seq):
    """If seq is an iterator, put its values into a list."""
    ...

def _trim_front(strings):
    """
    Trims zeros and decimal points
    """
    ...

def _validate_join_method(method):
    ...

