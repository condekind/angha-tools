"""
This type stub file was generated by pyright.
"""

import numpy as np
from pandas._libs import algos, hashtable as htable
from typing import Any, Optional

"""
Generic data algorithms. This module is experimental at the moment and not
intended for public consumption
"""
def _ensure_data(values, dtype: Optional[Any] = ...):
    """
    routine to ensure that our data is of the correct
    input dtype for lower-level routines

    This will coerce:
    - ints -> int64
    - uint -> uint64
    - bool -> uint64 (TODO this should be uint8)
    - datetimelike -> i8
    - datetime64tz -> i8 (in local tz)
    - categorical -> codes

    Parameters
    ----------
    values : array-like
    dtype : pandas_dtype, optional
        coerce to this dtype

    Returns
    -------
    (ndarray, pandas_dtype, algo dtype as a string)

    """
    ...

def _reconstruct_data(values, dtype, original):
    """
    reverse of _ensure_data

    Parameters
    ----------
    values : ndarray
    dtype : pandas_dtype
    original : ndarray-like

    Returns
    -------
    Index for extension types, otherwise ndarray casted to dtype

    """
    ...

def _ensure_arraylike(values):
    """
    ensure that we are arraylike if not already
    """
    ...

_hashtables = { 'float64': (htable.Float64HashTable, htable.Float64Vector),'uint64': (htable.UInt64HashTable, htable.UInt64Vector),'int64': (htable.Int64HashTable, htable.Int64Vector),'string': (htable.StringHashTable, htable.ObjectVector),'object': (htable.PyObjectHashTable, htable.ObjectVector) }
def _get_hashtable_algo(values):
    """
    Parameters
    ----------
    values : arraylike

    Returns
    -------
    tuples(hashtable class,
           vector class,
           values,
           dtype,
           ndtype)
    """
    ...

def _get_data_algo(values, func_map):
    ...

def match(to_match, values, na_sentinel=...):
    """
    Compute locations of to_match into values

    Parameters
    ----------
    to_match : array-like
        values to find positions of
    values : array-like
        Unique set of values
    na_sentinel : int, default -1
        Value to mark "not found"

    Examples
    --------

    Returns
    -------
    match : ndarray of integers
    """
    ...

def unique(values):
    """
    Hash table-based unique. Uniques are returned in order
    of appearance. This does NOT sort.

    Significantly faster than numpy.unique. Includes NA values.

    Parameters
    ----------
    values : 1d array-like

    Returns
    -------
    unique values.
      - If the input is an Index, the return is an Index
      - If the input is a Categorical dtype, the return is a Categorical
      - If the input is a Series/ndarray, the return will be an ndarray

    Examples
    --------
    >>> pd.unique(pd.Series([2, 1, 3, 3]))
    array([2, 1, 3])

    >>> pd.unique(pd.Series([2] + [1] * 5))
    array([2, 1])

    >>> pd.unique(Series([pd.Timestamp('20160101'),
    ...                   pd.Timestamp('20160101')]))
    array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')

    >>> pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),
    ...                      pd.Timestamp('20160101', tz='US/Eastern')]))
    array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],
          dtype=object)

    >>> pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),
    ...                     pd.Timestamp('20160101', tz='US/Eastern')]))
    DatetimeIndex(['2016-01-01 00:00:00-05:00'],
    ...           dtype='datetime64[ns, US/Eastern]', freq=None)

    >>> pd.unique(list('baabc'))
    array(['b', 'a', 'c'], dtype=object)

    An unordered Categorical will return categories in the
    order of appearance.

    >>> pd.unique(Series(pd.Categorical(list('baabc'))))
    [b, a, c]
    Categories (3, object): [b, a, c]

    >>> pd.unique(Series(pd.Categorical(list('baabc'),
    ...                                 categories=list('abc'))))
    [b, a, c]
    Categories (3, object): [b, a, c]

    An ordered Categorical preserves the category ordering.

    >>> pd.unique(Series(pd.Categorical(list('baabc'),
    ...                                 categories=list('abc'),
    ...                                 ordered=True)))
    [b, a, c]
    Categories (3, object): [a < b < c]

    An array of tuples

    >>> pd.unique([('a', 'b'), ('b', 'a'), ('a', 'c'), ('b', 'a')])
    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)

    See Also
    --------
    pandas.Index.unique
    pandas.Series.unique

    """
    ...

unique1d = unique
def isin(comps, values):
    """
    Compute the isin boolean array

    Parameters
    ----------
    comps: array-like
    values: array-like

    Returns
    -------
    boolean array same length as comps
    """
    ...

def factorize(values, sort: bool = ..., order: Optional[Any] = ..., na_sentinel=..., size_hint: Optional[Any] = ...):
    """
    Encode input values as an enumerated type or categorical variable

    Parameters
    ----------
    values : ndarray (1-d)
        Sequence
    sort : boolean, default False
        Sort by values
    na_sentinel : int, default -1
        Value to mark "not found"
    size_hint : hint to the hashtable sizer

    Returns
    -------
    labels : the indexer to the original array
    uniques : ndarray (1-d) or Index
        the unique values. Index is returned when passed values is Index or
        Series

    note: an array of Periods will ignore sort as it returns an always sorted
    PeriodIndex
    """
    ...

def value_counts(values, sort: bool = ..., ascending: bool = ..., normalize: bool = ..., bins: Optional[Any] = ..., dropna: bool = ...):
    """
    Compute a histogram of the counts of non-null values.

    Parameters
    ----------
    values : ndarray (1-d)
    sort : boolean, default True
        Sort by values
    ascending : boolean, default False
        Sort in ascending order
    normalize: boolean, default False
        If True then compute a relative histogram
    bins : integer, optional
        Rather than count values, group them into half-open bins,
        convenience for pd.cut, only works with numeric data
    dropna : boolean, default True
        Don't include counts of NaN

    Returns
    -------
    value_counts : Series

    """
    ...

def _value_counts_arraylike(values, dropna):
    """
    Parameters
    ----------
    values : arraylike
    dropna : boolean

    Returns
    -------
    (uniques, counts)

    """
    ...

def duplicated(values, keep=...):
    """
    Return boolean ndarray denoting duplicate values.

    .. versionadded:: 0.19.0

    Parameters
    ----------
    values : ndarray-like
        Array over which to check for duplicate values.
    keep : {'first', 'last', False}, default 'first'
        - ``first`` : Mark duplicates as ``True`` except for the first
          occurrence.
        - ``last`` : Mark duplicates as ``True`` except for the last
          occurrence.
        - False : Mark all duplicates as ``True``.

    Returns
    -------
    duplicated : ndarray
    """
    ...

def mode(values):
    """
    Returns the mode(s) of an array.

    Parameters
    ----------
    values : array-like
        Array over which to check for duplicate values.

    Returns
    -------
    mode : Series
    """
    ...

def rank(values, axis=..., method=..., na_option=..., ascending: bool = ..., pct: bool = ...):
    """
    Rank the values along a given axis.

    Parameters
    ----------
    values : array-like
        Array whose values will be ranked. The number of dimensions in this
        array must not exceed 2.
    axis : int, default 0
        Axis over which to perform rankings.
    method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'
        The method by which tiebreaks are broken during the ranking.
    na_option : {'keep', 'top'}, default 'keep'
        The method by which NaNs are placed in the ranking.
        - ``keep``: rank each NaN value with a NaN ranking
        - ``top``: replace each NaN with either +/- inf so that they
                   there are ranked at the top
    ascending : boolean, default True
        Whether or not the elements should be ranked in ascending order.
    pct : boolean, default False
        Whether or not to the display the returned rankings in integer form
        (e.g. 1, 2, 3) or in percentile form (e.g. 0.333..., 0.666..., 1).
    """
    ...

def checked_add_with_arr(arr, b, arr_mask: Optional[Any] = ..., b_mask: Optional[Any] = ...):
    """
    Perform array addition that checks for underflow and overflow.

    Performs the addition of an int64 array and an int64 integer (or array)
    but checks that they do not result in overflow first. For elements that
    are indicated to be NaN, whether or not there is overflow for that element
    is automatically ignored.

    Parameters
    ----------
    arr : array addend.
    b : array or scalar addend.
    arr_mask : boolean array or None
        array indicating which elements to exclude from checking
    b_mask : boolean array or boolean or None
        array or scalar indicating which element(s) to exclude from checking

    Returns
    -------
    sum : An array for elements x + b for each element x in arr if b is
          a scalar or an array for elements x + y for each element pair
          (x, y) in (arr, b).

    Raises
    ------
    OverflowError if any x + y exceeds the maximum or minimum int64 value.
    """
    ...

_rank1d_functions = { 'float64': algos.rank_1d_float64,'int64': algos.rank_1d_int64,'uint64': algos.rank_1d_uint64,'object': algos.rank_1d_object }
_rank2d_functions = { 'float64': algos.rank_2d_float64,'int64': algos.rank_2d_int64,'uint64': algos.rank_2d_uint64,'object': algos.rank_2d_object }
def quantile(x, q, interpolation_method=...):
    """
    Compute sample quantile or quantiles of the input array. For example, q=0.5
    computes the median.

    The `interpolation_method` parameter supports three values, namely
    `fraction` (default), `lower` and `higher`. Interpolation is done only,
    if the desired quantile lies between two data points `i` and `j`. For
    `fraction`, the result is an interpolated value between `i` and `j`;
    for `lower`, the result is `i`, for `higher` the result is `j`.

    Parameters
    ----------
    x : ndarray
        Values from which to extract score.
    q : scalar or array
        Percentile at which to extract score.
    interpolation_method : {'fraction', 'lower', 'higher'}, optional
        This optional parameter specifies the interpolation method to use,
        when the desired quantile lies between two data points `i` and `j`:

        - fraction: `i + (j - i)*fraction`, where `fraction` is the
                    fractional part of the index surrounded by `i` and `j`.
        -lower: `i`.
        - higher: `j`.

    Returns
    -------
    score : float
        Score at percentile.

    Examples
    --------
    >>> from scipy import stats
    >>> a = np.arange(100)
    >>> stats.scoreatpercentile(a, 50)
    49.5

    """
    ...

class SelectN(object):
    def __init__(self, obj, n, keep):
        self.obj = ...
        self.n = ...
        self.keep = ...
    
    def nlargest(self):
        ...
    
    def nsmallest(self):
        ...
    
    @staticmethod
    def is_valid_dtype_n_method(dtype):
        """
        Helper function to determine if dtype is valid for
        nsmallest/nlargest methods
        """
        ...
    


class SelectNSeries(SelectN):
    """
    Implement n largest/smallest for Series

    Parameters
    ----------
    obj : Series
    n : int
    keep : {'first', 'last'}, default 'first'

    Returns
    -------
    nordered : Series
    """
    def compute(self, method):
        ...
    


class SelectNFrame(SelectN):
    """
    Implement n largest/smallest for DataFrame

    Parameters
    ----------
    obj : DataFrame
    n : int
    keep : {'first', 'last'}, default 'first'
    columns : list or str

    Returns
    -------
    nordered : DataFrame
    """
    def __init__(self, obj, n, keep, columns):
        self.columns = ...
    
    def compute(self, method):
        ...
    


def _view_wrapper(f, arr_dtype: Optional[Any] = ..., out_dtype: Optional[Any] = ..., fill_wrap: Optional[Any] = ...):
    ...

def _convert_wrapper(f, conv_dtype):
    ...

def _take_2d_multi_object(arr, indexer, out, fill_value, mask_info):
    ...

def _take_nd_object(arr, indexer, out, axis, fill_value, mask_info):
    ...

_take_1d_dict = { ('int8', 'int8'): algos.take_1d_int8_int8,('int8', 'int32'): algos.take_1d_int8_int32,('int8', 'int64'): algos.take_1d_int8_int64,('int8', 'float64'): algos.take_1d_int8_float64,('int16', 'int16'): algos.take_1d_int16_int16,('int16', 'int32'): algos.take_1d_int16_int32,('int16', 'int64'): algos.take_1d_int16_int64,('int16', 'float64'): algos.take_1d_int16_float64,('int32', 'int32'): algos.take_1d_int32_int32,('int32', 'int64'): algos.take_1d_int32_int64,('int32', 'float64'): algos.take_1d_int32_float64,('int64', 'int64'): algos.take_1d_int64_int64,('int64', 'float64'): algos.take_1d_int64_float64,('float32', 'float32'): algos.take_1d_float32_float32,('float32', 'float64'): algos.take_1d_float32_float64,('float64', 'float64'): algos.take_1d_float64_float64,('object', 'object'): algos.take_1d_object_object,('bool', 'bool'): _view_wrapper(algos.take_1d_bool_bool, np.uint8, np.uint8),('bool', 'object'): _view_wrapper(algos.take_1d_bool_object, np.uint8, None),('datetime64[ns]', 'datetime64[ns]'): _view_wrapper(algos.take_1d_int64_int64, np.int64, np.int64, np.int64) }
_take_2d_axis0_dict = { ('int8', 'int8'): algos.take_2d_axis0_int8_int8,('int8', 'int32'): algos.take_2d_axis0_int8_int32,('int8', 'int64'): algos.take_2d_axis0_int8_int64,('int8', 'float64'): algos.take_2d_axis0_int8_float64,('int16', 'int16'): algos.take_2d_axis0_int16_int16,('int16', 'int32'): algos.take_2d_axis0_int16_int32,('int16', 'int64'): algos.take_2d_axis0_int16_int64,('int16', 'float64'): algos.take_2d_axis0_int16_float64,('int32', 'int32'): algos.take_2d_axis0_int32_int32,('int32', 'int64'): algos.take_2d_axis0_int32_int64,('int32', 'float64'): algos.take_2d_axis0_int32_float64,('int64', 'int64'): algos.take_2d_axis0_int64_int64,('int64', 'float64'): algos.take_2d_axis0_int64_float64,('float32', 'float32'): algos.take_2d_axis0_float32_float32,('float32', 'float64'): algos.take_2d_axis0_float32_float64,('float64', 'float64'): algos.take_2d_axis0_float64_float64,('object', 'object'): algos.take_2d_axis0_object_object,('bool', 'bool'): _view_wrapper(algos.take_2d_axis0_bool_bool, np.uint8, np.uint8),('bool', 'object'): _view_wrapper(algos.take_2d_axis0_bool_object, np.uint8, None),('datetime64[ns]', 'datetime64[ns]'): _view_wrapper(algos.take_2d_axis0_int64_int64, np.int64, np.int64, fill_wrap=np.int64) }
_take_2d_axis1_dict = { ('int8', 'int8'): algos.take_2d_axis1_int8_int8,('int8', 'int32'): algos.take_2d_axis1_int8_int32,('int8', 'int64'): algos.take_2d_axis1_int8_int64,('int8', 'float64'): algos.take_2d_axis1_int8_float64,('int16', 'int16'): algos.take_2d_axis1_int16_int16,('int16', 'int32'): algos.take_2d_axis1_int16_int32,('int16', 'int64'): algos.take_2d_axis1_int16_int64,('int16', 'float64'): algos.take_2d_axis1_int16_float64,('int32', 'int32'): algos.take_2d_axis1_int32_int32,('int32', 'int64'): algos.take_2d_axis1_int32_int64,('int32', 'float64'): algos.take_2d_axis1_int32_float64,('int64', 'int64'): algos.take_2d_axis1_int64_int64,('int64', 'float64'): algos.take_2d_axis1_int64_float64,('float32', 'float32'): algos.take_2d_axis1_float32_float32,('float32', 'float64'): algos.take_2d_axis1_float32_float64,('float64', 'float64'): algos.take_2d_axis1_float64_float64,('object', 'object'): algos.take_2d_axis1_object_object,('bool', 'bool'): _view_wrapper(algos.take_2d_axis1_bool_bool, np.uint8, np.uint8),('bool', 'object'): _view_wrapper(algos.take_2d_axis1_bool_object, np.uint8, None),('datetime64[ns]', 'datetime64[ns]'): _view_wrapper(algos.take_2d_axis1_int64_int64, np.int64, np.int64, fill_wrap=np.int64) }
_take_2d_multi_dict = { ('int8', 'int8'): algos.take_2d_multi_int8_int8,('int8', 'int32'): algos.take_2d_multi_int8_int32,('int8', 'int64'): algos.take_2d_multi_int8_int64,('int8', 'float64'): algos.take_2d_multi_int8_float64,('int16', 'int16'): algos.take_2d_multi_int16_int16,('int16', 'int32'): algos.take_2d_multi_int16_int32,('int16', 'int64'): algos.take_2d_multi_int16_int64,('int16', 'float64'): algos.take_2d_multi_int16_float64,('int32', 'int32'): algos.take_2d_multi_int32_int32,('int32', 'int64'): algos.take_2d_multi_int32_int64,('int32', 'float64'): algos.take_2d_multi_int32_float64,('int64', 'int64'): algos.take_2d_multi_int64_int64,('int64', 'float64'): algos.take_2d_multi_int64_float64,('float32', 'float32'): algos.take_2d_multi_float32_float32,('float32', 'float64'): algos.take_2d_multi_float32_float64,('float64', 'float64'): algos.take_2d_multi_float64_float64,('object', 'object'): algos.take_2d_multi_object_object,('bool', 'bool'): _view_wrapper(algos.take_2d_multi_bool_bool, np.uint8, np.uint8),('bool', 'object'): _view_wrapper(algos.take_2d_multi_bool_object, np.uint8, None),('datetime64[ns]', 'datetime64[ns]'): _view_wrapper(algos.take_2d_multi_int64_int64, np.int64, np.int64, fill_wrap=np.int64) }
def _get_take_nd_function(ndim, arr_dtype, out_dtype, axis=..., mask_info: Optional[Any] = ...):
    ...

def take_nd(arr, indexer, axis=..., out: Optional[Any] = ..., fill_value=..., mask_info: Optional[Any] = ..., allow_fill: bool = ...):
    """
    Specialized Cython take which sets NaN values in one pass

    Parameters
    ----------
    arr : ndarray
        Input array
    indexer : ndarray
        1-D array of indices to take, subarrays corresponding to -1 value
        indicies are filed with fill_value
    axis : int, default 0
        Axis to take from
    out : ndarray or None, default None
        Optional output array, must be appropriate type to hold input and
        fill_value together, if indexer has any -1 value entries; call
        _maybe_promote to determine this type for any fill_value
    fill_value : any, default np.nan
        Fill value to replace -1 values with
    mask_info : tuple of (ndarray, boolean)
        If provided, value should correspond to:
            (indexer != -1, (indexer != -1).any())
        If not provided, it will be computed internally if necessary
    allow_fill : boolean, default True
        If False, indexer is assumed to contain no -1 values so no filling
        will be done.  This short-circuits computation of a mask.  Result is
        undefined if allow_fill == False and -1 is present in indexer.
    """
    ...

take_1d = take_nd
def take_2d_multi(arr, indexer, out: Optional[Any] = ..., fill_value=..., mask_info: Optional[Any] = ..., allow_fill: bool = ...):
    """
    Specialized Cython take which sets NaN values in one pass
    """
    ...

_diff_special = { 'float64': algos.diff_2d_float64,'float32': algos.diff_2d_float32,'int64': algos.diff_2d_int64,'int32': algos.diff_2d_int32,'int16': algos.diff_2d_int16,'int8': algos.diff_2d_int8 }
def diff(arr, n, axis=...):
    """
    difference of n between self,
    analogous to s-s.shift(n)

    Parameters
    ----------
    arr : ndarray
    n : int
        number of periods
    axis : int
        axis to shift on

    Returns
    -------
    shifted

    """
    ...

