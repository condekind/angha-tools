"""
This type stub file was generated by pyright.
"""

from pandas.core import base, generic
from pandas.util._decorators import Appender, Substitution, deprecate_kwarg
from typing import Any, Optional

"""
Data structure for 1-dimensional cross-sectional and time series data
"""
__all__ = ['Series']
_shared_doc_kwargs = dict(axes='index', klass='Series', axes_single_arg="{0, 'index'}", inplace="""inplace : boolean, default False
        If True, performs operation inplace and returns None.""", unique='np.ndarray', duplicated='Series', optional_by='', optional_mapper='', optional_labels='', optional_axis='', versionadded_to_excel='\n    .. versionadded:: 0.20.0\n')
def remove_na(arr):
    """
    DEPRECATED : this function will be removed in a future version.
    """
    ...

def _coerce_method(converter):
    """ install the scalar coercion methods """
    ...

class Series(base.IndexOpsMixin, generic.NDFrame):
    """
    One-dimensional ndarray with axis labels (including time series).

    Labels need not be unique but must be a hashable type. The object
    supports both integer- and label-based indexing and provides a host of
    methods for performing operations involving the index. Statistical
    methods from ndarray have been overridden to automatically exclude
    missing data (currently represented as NaN).

    Operations between Series (+, -, /, *, **) align values based on their
    associated index values-- they need not be the same length. The result
    index will be the sorted union of the two indexes.

    Parameters
    ----------
    data : array-like, dict, or scalar value
        Contains data stored in Series
    index : array-like or Index (1d)
        Values must be hashable and have the same length as `data`.
        Non-unique index values are allowed. Will default to
        RangeIndex(len(data)) if not provided. If both a dict and index
        sequence are used, the index will override the keys found in the
        dict.
    dtype : numpy.dtype or None
        If None, dtype will be inferred
    copy : boolean, default False
        Copy input data
    """
    _metadata = ...
    _accessors = ...
    _deprecations = ...
    _allow_index_ops = ...
    def __init__(self, data: Optional[Any] = ..., index: Optional[Any] = ..., dtype: Optional[Any] = ..., name: Optional[Any] = ..., copy: bool = ..., fastpath: bool = ...):
        self.name = ...
    
    @classmethod
    def from_array(cls, arr, index: Optional[Any] = ..., name: Optional[Any] = ..., dtype: Optional[Any] = ..., copy: bool = ..., fastpath: bool = ...):
        ...
    
    @property
    def _constructor(self):
        ...
    
    @property
    def _constructor_expanddim(self):
        ...
    
    @property
    def _can_hold_na(self):
        ...
    
    _index = ...
    def _set_axis(self, axis, labels, fastpath: bool = ...):
        """ override generic, we want to set the _typ here """
        ...
    
    def _set_subtyp(self, is_all_dates):
        ...
    
    def _update_inplace(self, result, **kwargs):
        ...
    
    @property
    def name(self):
        ...
    
    @name.setter
    def name(self, value):
        ...
    
    @property
    def dtype(self):
        """ return the dtype object of the underlying data """
        ...
    
    @property
    def dtypes(self):
        """ return the dtype object of the underlying data """
        ...
    
    @property
    def ftype(self):
        """ return if the data is sparse|dense """
        ...
    
    @property
    def ftypes(self):
        """ return if the data is sparse|dense """
        ...
    
    @property
    def values(self):
        """
        Return Series as ndarray or ndarray-like
        depending on the dtype

        Returns
        -------
        arr : numpy.ndarray or ndarray-like

        Examples
        --------
        >>> pd.Series([1, 2, 3]).values
        array([1, 2, 3])

        >>> pd.Series(list('aabc')).values
        array(['a', 'a', 'b', 'c'], dtype=object)

        >>> pd.Series(list('aabc')).astype('category').values
        [a, a, b, c]
        Categories (3, object): [a, b, c]

        Timezone aware datetime data is converted to UTC:

        >>> pd.Series(pd.date_range('20130101', periods=3,
        ...                         tz='US/Eastern')).values
        array(['2013-01-01T05:00:00.000000000',
               '2013-01-02T05:00:00.000000000',
               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')

        """
        ...
    
    @property
    def _values(self):
        """ return the internal repr of this data """
        ...
    
    def _formatting_values(self):
        """Return the values that can be formatted (used by SeriesFormatter
        and DataFrameFormatter)
        """
        ...
    
    def get_values(self):
        """ same as values (but handles sparseness conversions); is a view """
        ...
    
    @property
    def asobject(self):
        """
        return object Series which contains boxed values

        *this is an internal non-public method*
        """
        ...
    
    def ravel(self, order=...):
        """
        Return the flattened underlying data as an ndarray

        See also
        --------
        numpy.ndarray.ravel
        """
        ...
    
    def compress(self, condition, *args, **kwargs):
        """
        Return selected slices of an array along given axis as a Series

        See also
        --------
        numpy.ndarray.compress
        """
        ...
    
    def nonzero(self):
        """
        Return the indices of the elements that are non-zero

        This method is equivalent to calling `numpy.nonzero` on the
        series data. For compatability with NumPy, the return value is
        the same (a tuple with an array of indices for each dimension),
        but it will always be a one-item tuple because series only have
        one dimension.

        Examples
        --------
        >>> s = pd.Series([0, 3, 0, 4])
        >>> s.nonzero()
        (array([1, 3]),)
        >>> s.iloc[s.nonzero()[0]]
        1    3
        3    4
        dtype: int64

        See Also
        --------
        numpy.nonzero
        """
        ...
    
    def put(self, *args, **kwargs):
        """
        Applies the `put` method to its `values` attribute
        if it has one.

        See also
        --------
        numpy.ndarray.put
        """
        ...
    
    def __len__(self):
        """
        return the length of the Series
        """
        ...
    
    def view(self, dtype: Optional[Any] = ...):
        ...
    
    def __array__(self, result: Optional[Any] = ...):
        """
        the array interface, return my values
        """
        ...
    
    def __array_wrap__(self, result, context: Optional[Any] = ...):
        """
        Gets called after a ufunc
        """
        ...
    
    def __array_prepare__(self, result, context: Optional[Any] = ...):
        """
        Gets called prior to a ufunc
        """
        ...
    
    @property
    def real(self):
        ...
    
    @real.setter
    def real(self, v):
        ...
    
    @property
    def imag(self):
        ...
    
    @imag.setter
    def imag(self, v):
        ...
    
    __float__ = ...
    __long__ = ...
    __int__ = ...
    def _unpickle_series_compat(self, state):
        ...
    
    @property
    def axes(self):
        """Return a list of the row axis labels"""
        ...
    
    def _ixs(self, i, axis=...):
        """
        Return the i-th value or values in the Series by location

        Parameters
        ----------
        i : int, slice, or sequence of integers

        Returns
        -------
        value : scalar (int) or Series (slice, sequence)
        """
        ...
    
    @property
    def _is_mixed_type(self):
        ...
    
    def _slice(self, slobj, axis=..., kind: Optional[Any] = ...):
        ...
    
    def __getitem__(self, key):
        ...
    
    def _get_with(self, key):
        ...
    
    def _get_values_tuple(self, key):
        ...
    
    def _get_values(self, indexer):
        ...
    
    def __setitem__(self, key, value):
        ...
    
    def _set_with_engine(self, key, value):
        ...
    
    def _set_with(self, key, value):
        ...
    
    def _set_labels(self, key, value):
        ...
    
    def _set_values(self, key, value):
        ...
    
    @deprecate_kwarg(old_arg_name='reps', new_arg_name='repeats')
    def repeat(self, repeats, *args, **kwargs):
        """
        Repeat elements of an Series. Refer to `numpy.ndarray.repeat`
        for more information about the `repeats` argument.

        See also
        --------
        numpy.ndarray.repeat
        """
        ...
    
    def reshape(self, *args, **kwargs):
        """
        .. deprecated:: 0.19.0
           Calling this method will raise an error. Please call
           ``.values.reshape(...)`` instead.

        return an ndarray with the values shape
        if the specified shape matches exactly the current shape, then
        return self (for compat)

        See also
        --------
        numpy.ndarray.reshape
        """
        ...
    
    def get_value(self, label, takeable: bool = ...):
        """
        Quickly retrieve single value at passed index label

        .. deprecated:: 0.21.0

        Please use .at[] or .iat[] accessors.

        Parameters
        ----------
        index : label
        takeable : interpret the index as indexers, default False

        Returns
        -------
        value : scalar value
        """
        ...
    
    def _get_value(self, label, takeable: bool = ...):
        ...
    
    def set_value(self, label, value, takeable: bool = ...):
        """
        Quickly set single value at passed label. If label is not contained, a
        new object is created with the label placed at the end of the result
        index

        .. deprecated:: 0.21.0

        Please use .at[] or .iat[] accessors.

        Parameters
        ----------
        label : object
            Partial indexing with MultiIndex not allowed
        value : object
            Scalar value
        takeable : interpret the index as indexers, default False

        Returns
        -------
        series : Series
            If label is contained, will be reference to calling Series,
            otherwise a new object
        """
        ...
    
    def _set_value(self, label, value, takeable: bool = ...):
        ...
    
    def reset_index(self, level: Optional[Any] = ..., drop: bool = ..., name: Optional[Any] = ..., inplace: bool = ...):
        """
        Analogous to the :meth:`pandas.DataFrame.reset_index` function, see
        docstring there.

        Parameters
        ----------
        level : int, str, tuple, or list, default None
            Only remove the given levels from the index. Removes all levels by
            default
        drop : boolean, default False
            Do not try to insert index into dataframe columns
        name : object, default None
            The name of the column corresponding to the Series values
        inplace : boolean, default False
            Modify the Series in place (do not create a new object)

        Returns
        ----------
        resetted : DataFrame, or Series if drop == True

        Examples
        --------
        >>> s = pd.Series([1, 2, 3, 4], index=pd.Index(['a', 'b', 'c', 'd'],
        ...                                            name = 'idx'))
        >>> s.reset_index()
           index  0
        0      0  1
        1      1  2
        2      2  3
        3      3  4

        >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo',
        ...                     'foo', 'qux', 'qux']),
        ...           np.array(['one', 'two', 'one', 'two', 'one', 'two',
        ...                     'one', 'two'])]
        >>> s2 = pd.Series(
        ...     np.random.randn(8),
        ...     index=pd.MultiIndex.from_arrays(arrays,
        ...                                     names=['a', 'b']))
        >>> s2.reset_index(level='a')
               a         0
        b
        one  bar -0.286320
        two  bar -0.587934
        one  baz  0.710491
        two  baz -1.429006
        one  foo  0.790700
        two  foo  0.824863
        one  qux -0.718963
        two  qux -0.055028
        """
        ...
    
    def __unicode__(self):
        """
        Return a string representation for a particular DataFrame

        Invoked by unicode(df) in py2 only. Yields a Unicode String in both
        py2/py3.
        """
        ...
    
    def to_string(self, buf: Optional[Any] = ..., na_rep=..., float_format: Optional[Any] = ..., header: bool = ..., index: bool = ..., length: bool = ..., dtype: bool = ..., name: bool = ..., max_rows: Optional[Any] = ...):
        """
        Render a string representation of the Series

        Parameters
        ----------
        buf : StringIO-like, optional
            buffer to write to
        na_rep : string, optional
            string representation of NAN to use, default 'NaN'
        float_format : one-parameter function, optional
            formatter function to apply to columns' elements if they are floats
            default None
        header: boolean, default True
            Add the Series header (index name)
        index : bool, optional
            Add index (row) labels, default True
        length : boolean, default False
            Add the Series length
        dtype : boolean, default False
            Add the Series dtype
        name : boolean, default False
            Add the Series name if not None
        max_rows : int, optional
            Maximum number of rows to show before truncating. If None, show
            all.

        Returns
        -------
        formatted : string (if not buffer passed)
        """
        ...
    
    def iteritems(self):
        """
        Lazily iterate over (index, value) tuples
        """
        ...
    
    items = ...
    def keys(self):
        """Alias for index"""
        ...
    
    def to_dict(self, into=...):
        """
        Convert Series to {label -> value} dict or dict-like object.

        Parameters
        ----------
        into : class, default dict
            The collections.Mapping subclass to use as the return
            object. Can be the actual class or an empty
            instance of the mapping type you want.  If you want a
            collections.defaultdict, you must pass it initialized.

            .. versionadded:: 0.21.0

        Returns
        -------
        value_dict : collections.Mapping

        Examples
        --------
        >>> s = pd.Series([1, 2, 3, 4])
        >>> s.to_dict()
        {0: 1, 1: 2, 2: 3, 3: 4}
        >>> from collections import OrderedDict, defaultdict
        >>> s.to_dict(OrderedDict)
        OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])
        >>> dd = defaultdict(list)
        >>> s.to_dict(dd)
        defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})
        """
        ...
    
    def to_frame(self, name: Optional[Any] = ...):
        """
        Convert Series to DataFrame

        Parameters
        ----------
        name : object, default None
            The passed name should substitute for the series name (if it has
            one).

        Returns
        -------
        data_frame : DataFrame
        """
        ...
    
    def to_sparse(self, kind=..., fill_value: Optional[Any] = ...):
        """
        Convert Series to SparseSeries

        Parameters
        ----------
        kind : {'block', 'integer'}
        fill_value : float, defaults to NaN (missing)

        Returns
        -------
        sp : SparseSeries
        """
        ...
    
    def _set_name(self, name, inplace: bool = ...):
        """
        Set the Series name.

        Parameters
        ----------
        name : str
        inplace : bool
            whether to modify `self` directly or return a copy
        """
        ...
    
    def count(self, level: Optional[Any] = ...):
        """
        Return number of non-NA/null observations in the Series

        Parameters
        ----------
        level : int or level name, default None
            If the axis is a MultiIndex (hierarchical), count along a
            particular level, collapsing into a smaller Series

        Returns
        -------
        nobs : int or Series (if level specified)
        """
        ...
    
    def mode(self):
        """Return the mode(s) of the dataset.

        Always returns Series even if only one value is returned.

        Returns
        -------
        modes : Series (sorted)
        """
        ...
    
    @Appender(base._shared_docs['unique'] % _shared_doc_kwargs)
    def unique(self):
        ...
    
    @Appender(base._shared_docs['drop_duplicates'] % _shared_doc_kwargs)
    def drop_duplicates(self, keep=..., inplace: bool = ...):
        ...
    
    @Appender(base._shared_docs['duplicated'] % _shared_doc_kwargs)
    def duplicated(self, keep=...):
        ...
    
    def idxmin(self, axis: Optional[Any] = ..., skipna: bool = ..., *args, **kwargs):
        """
        Index *label* of the first occurrence of minimum of values.

        Parameters
        ----------
        skipna : boolean, default True
            Exclude NA/null values. If the entire Series is NA, the result
            will be NA.

        Raises
        ------
        ValueError
            * If the Series is empty

        Returns
        -------
        idxmin : Index of minimum of values

        Notes
        -----
        This method is the Series version of ``ndarray.argmin``. This method
        returns the label of the minimum, while ``ndarray.argmin`` returns
        the position. To get the position, use ``series.values.argmin()``.

        See Also
        --------
        DataFrame.idxmin
        numpy.ndarray.argmin
        """
        ...
    
    def idxmax(self, axis: Optional[Any] = ..., skipna: bool = ..., *args, **kwargs):
        """
        Index *label* of the first occurrence of maximum of values.

        Parameters
        ----------
        skipna : boolean, default True
            Exclude NA/null values. If the entire Series is NA, the result
            will be NA.

        Raises
        ------
        ValueError
            * If the Series is empty

        Returns
        -------
        idxmax : Index of maximum of values

        Notes
        -----
        This method is the Series version of ``ndarray.argmax``. This method
        returns the label of the maximum, while ``ndarray.argmax`` returns
        the position. To get the position, use ``series.values.argmax()``.

        See Also
        --------
        DataFrame.idxmax
        numpy.ndarray.argmax
        """
        ...
    
    argmin = ...
    argmax = ...
    def round(self, decimals=..., *args, **kwargs):
        """
        Round each value in a Series to the given number of decimals.

        Parameters
        ----------
        decimals : int
            Number of decimal places to round to (default: 0).
            If decimals is negative, it specifies the number of
            positions to the left of the decimal point.

        Returns
        -------
        Series object

        See Also
        --------
        numpy.around
        DataFrame.round

        """
        ...
    
    def quantile(self, q=..., interpolation=...):
        """
        Return value at the given quantile, a la numpy.percentile.

        Parameters
        ----------
        q : float or array-like, default 0.5 (50% quantile)
            0 <= q <= 1, the quantile(s) to compute
        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}
            .. versionadded:: 0.18.0

            This optional parameter specifies the interpolation method to use,
            when the desired quantile lies between two data points `i` and `j`:

                * linear: `i + (j - i) * fraction`, where `fraction` is the
                  fractional part of the index surrounded by `i` and `j`.
                * lower: `i`.
                * higher: `j`.
                * nearest: `i` or `j` whichever is nearest.
                * midpoint: (`i` + `j`) / 2.

        Returns
        -------
        quantile : float or Series
            if ``q`` is an array, a Series will be returned where the
            index is ``q`` and the values are the quantiles.

        Examples
        --------
        >>> s = Series([1, 2, 3, 4])
        >>> s.quantile(.5)
        2.5
        >>> s.quantile([.25, .5, .75])
        0.25    1.75
        0.50    2.50
        0.75    3.25
        dtype: float64

        """
        ...
    
    def corr(self, other, method=..., min_periods: Optional[Any] = ...):
        """
        Compute correlation with `other` Series, excluding missing values

        Parameters
        ----------
        other : Series
        method : {'pearson', 'kendall', 'spearman'}
            * pearson : standard correlation coefficient
            * kendall : Kendall Tau correlation coefficient
            * spearman : Spearman rank correlation
        min_periods : int, optional
            Minimum number of observations needed to have a valid result


        Returns
        -------
        correlation : float
        """
        ...
    
    def cov(self, other, min_periods: Optional[Any] = ...):
        """
        Compute covariance with Series, excluding missing values

        Parameters
        ----------
        other : Series
        min_periods : int, optional
            Minimum number of observations needed to have a valid result

        Returns
        -------
        covariance : float

        Normalized by N-1 (unbiased estimator).
        """
        ...
    
    def diff(self, periods=...):
        """
        1st discrete difference of object

        Parameters
        ----------
        periods : int, default 1
            Periods to shift for forming difference

        Returns
        -------
        diffed : Series
        """
        ...
    
    def autocorr(self, lag=...):
        """
        Lag-N autocorrelation

        Parameters
        ----------
        lag : int, default 1
            Number of lags to apply before performing autocorrelation.

        Returns
        -------
        autocorr : float
        """
        ...
    
    def dot(self, other):
        """
        Matrix multiplication with DataFrame or inner-product with Series
        objects

        Parameters
        ----------
        other : Series or DataFrame

        Returns
        -------
        dot_product : scalar or Series
        """
        ...
    
    @Substitution(klass='Series')
    @Appender(base._shared_docs['searchsorted'])
    @deprecate_kwarg(old_arg_name='v', new_arg_name='value')
    def searchsorted(self, value, side=..., sorter: Optional[Any] = ...):
        ...
    
    def append(self, to_append, ignore_index: bool = ..., verify_integrity: bool = ...):
        """
        Concatenate two or more Series.

        Parameters
        ----------
        to_append : Series or list/tuple of Series
        ignore_index : boolean, default False
            If True, do not use the index labels.

            .. versionadded: 0.19.0

        verify_integrity : boolean, default False
            If True, raise Exception on creating index with duplicates

        Notes
        -----
        Iteratively appending to a Series can be more computationally intensive
        than a single concatenate. A better solution is to append values to a
        list and then concatenate the list with the original Series all at
        once.

        See also
        --------
        pandas.concat : General function to concatenate DataFrame, Series
            or Panel objects

        Returns
        -------
        appended : Series

        Examples
        --------
        >>> s1 = pd.Series([1, 2, 3])
        >>> s2 = pd.Series([4, 5, 6])
        >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])
        >>> s1.append(s2)
        0    1
        1    2
        2    3
        0    4
        1    5
        2    6
        dtype: int64

        >>> s1.append(s3)
        0    1
        1    2
        2    3
        3    4
        4    5
        5    6
        dtype: int64

        With `ignore_index` set to True:

        >>> s1.append(s2, ignore_index=True)
        0    1
        1    2
        2    3
        3    4
        4    5
        5    6
        dtype: int64

        With `verify_integrity` set to True:

        >>> s1.append(s2, verify_integrity=True)
        Traceback (most recent call last):
        ...
        ValueError: Indexes have overlapping values: [0, 1, 2]


        """
        ...
    
    def _binop(self, other, func, level: Optional[Any] = ..., fill_value: Optional[Any] = ...):
        """
        Perform generic binary operation with optional fill value

        Parameters
        ----------
        other : Series
        func : binary operator
        fill_value : float or object
            Value to substitute for NA/null values. If both Series are NA in a
            location, the result will be NA regardless of the passed fill value
        level : int or level name, default None
            Broadcast across a level, matching Index values on the
            passed MultiIndex level

        Returns
        -------
        combined : Series
        """
        ...
    
    def combine(self, other, func, fill_value=...):
        """
        Perform elementwise binary operation on two Series using given function
        with optional fill value when an index is missing from one Series or
        the other

        Parameters
        ----------
        other : Series or scalar value
        func : function
            Function that takes two scalars as inputs and return a scalar
        fill_value : scalar value

        Returns
        -------
        result : Series

        Examples
        --------
        >>> s1 = Series([1, 2])
        >>> s2 = Series([0, 3])
        >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)
        0    0
        1    2
        dtype: int64

        See Also
        --------
        Series.combine_first : Combine Series values, choosing the calling
            Series's values first
        """
        ...
    
    def combine_first(self, other):
        """
        Combine Series values, choosing the calling Series's values
        first. Result index will be the union of the two indexes

        Parameters
        ----------
        other : Series

        Returns
        -------
        combined : Series

        Examples
        --------
        >>> s1 = pd.Series([1, np.nan])
        >>> s2 = pd.Series([3, 4])
        >>> s1.combine_first(s2)
        0    1.0
        1    4.0
        dtype: float64

        See Also
        --------
        Series.combine : Perform elementwise operation on two Series
            using a given function
        """
        ...
    
    def update(self, other):
        """
        Modify Series in place using non-NA values from passed
        Series. Aligns on index

        Parameters
        ----------
        other : Series

        Examples
        --------
        >>> s = pd.Series([1, 2, 3])
        >>> s.update(pd.Series([4, 5, 6]))
        >>> s
        0    4
        1    5
        2    6
        dtype: int64

        >>> s = pd.Series(['a', 'b', 'c'])
        >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))
        >>> s
        0    d
        1    b
        2    e
        dtype: object

        >>> s = pd.Series([1, 2, 3])
        >>> s.update(pd.Series([4, 5, 6, 7, 8]))
        >>> s
        0    4
        1    5
        2    6
        dtype: int64

        If ``other`` contains NaNs the corresponding values are not updated
        in the original Series.

        >>> s = pd.Series([1, 2, 3])
        >>> s.update(pd.Series([4, np.nan, 6]))
        >>> s
        0    4
        1    2
        2    6
        dtype: int64

        """
        ...
    
    @Appender(generic._shared_docs['sort_values'] % _shared_doc_kwargs)
    def sort_values(self, axis=..., ascending: bool = ..., inplace: bool = ..., kind=..., na_position=...):
        ...
    
    @Appender(generic._shared_docs['sort_index'] % _shared_doc_kwargs)
    def sort_index(self, axis=..., level: Optional[Any] = ..., ascending: bool = ..., inplace: bool = ..., kind=..., na_position=..., sort_remaining: bool = ...):
        ...
    
    def argsort(self, axis=..., kind=..., order: Optional[Any] = ...):
        """
        Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,
        and places the result in the same locations as the non-NA values

        Parameters
        ----------
        axis : int (can only be zero)
        kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'
            Choice of sorting algorithm. See np.sort for more
            information. 'mergesort' is the only stable algorithm
        order : ignored

        Returns
        -------
        argsorted : Series, with -1 indicated where nan values are present

        See also
        --------
        numpy.ndarray.argsort
        """
        ...
    
    def nlargest(self, n=..., keep=...):
        """
        Return the largest `n` elements.

        Parameters
        ----------
        n : int
            Return this many descending sorted values
        keep : {'first', 'last'}, default 'first'
            Where there are duplicate values:
            - ``first`` : take the first occurrence.
            - ``last`` : take the last occurrence.

        Returns
        -------
        top_n : Series
            The n largest values in the Series, in sorted order

        Notes
        -----
        Faster than ``.sort_values(ascending=False).head(n)`` for small `n`
        relative to the size of the ``Series`` object.

        See Also
        --------
        Series.nsmallest

        Examples
        --------
        >>> import pandas as pd
        >>> import numpy as np
        >>> s = pd.Series(np.random.randn(10**6))
        >>> s.nlargest(10)  # only sorts up to the N requested
        219921    4.644710
        82124     4.608745
        421689    4.564644
        425277    4.447014
        718691    4.414137
        43154     4.403520
        283187    4.313922
        595519    4.273635
        503969    4.250236
        121637    4.240952
        dtype: float64
        """
        ...
    
    def nsmallest(self, n=..., keep=...):
        """
        Return the smallest `n` elements.

        Parameters
        ----------
        n : int
            Return this many ascending sorted values
        keep : {'first', 'last'}, default 'first'
            Where there are duplicate values:
            - ``first`` : take the first occurrence.
            - ``last`` : take the last occurrence.

        Returns
        -------
        bottom_n : Series
            The n smallest values in the Series, in sorted order

        Notes
        -----
        Faster than ``.sort_values().head(n)`` for small `n` relative to
        the size of the ``Series`` object.

        See Also
        --------
        Series.nlargest

        Examples
        --------
        >>> import pandas as pd
        >>> import numpy as np
        >>> s = pd.Series(np.random.randn(10**6))
        >>> s.nsmallest(10)  # only sorts up to the N requested
        288532   -4.954580
        732345   -4.835960
        64803    -4.812550
        446457   -4.609998
        501225   -4.483945
        669476   -4.472935
        973615   -4.401699
        621279   -4.355126
        773916   -4.347355
        359919   -4.331927
        dtype: float64
        """
        ...
    
    def sortlevel(self, level=..., ascending: bool = ..., sort_remaining: bool = ...):
        """
        DEPRECATED: use :meth:`Series.sort_index`

        Sort Series with MultiIndex by chosen level. Data will be
        lexicographically sorted by the chosen level followed by the other
        levels (in order)

        Parameters
        ----------
        level : int or level name, default None
        ascending : bool, default True

        Returns
        -------
        sorted : Series

        See Also
        --------
        Series.sort_index(level=...)

        """
        ...
    
    def swaplevel(self, i=..., j=..., copy: bool = ...):
        """
        Swap levels i and j in a MultiIndex

        Parameters
        ----------
        i, j : int, string (can be mixed)
            Level of index to be swapped. Can pass level name as string.

        Returns
        -------
        swapped : Series

        .. versionchanged:: 0.18.1

           The indexes ``i`` and ``j`` are now optional, and default to
           the two innermost levels of the index.

        """
        ...
    
    def reorder_levels(self, order):
        """
        Rearrange index levels using input order. May not drop or duplicate
        levels

        Parameters
        ----------
        order : list of int representing new level order.
               (reference level by number or key)
        axis : where to reorder levels

        Returns
        -------
        type of caller (new object)
        """
        ...
    
    def unstack(self, level=..., fill_value: Optional[Any] = ...):
        """
        Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.
        The level involved will automatically get sorted.

        Parameters
        ----------
        level : int, string, or list of these, default last level
            Level(s) to unstack, can pass level name
        fill_value : replace NaN with this value if the unstack produces
            missing values

            .. versionadded: 0.18.0

        Examples
        --------
        >>> s = pd.Series([1, 2, 3, 4],
        ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))
        >>> s
        one  a    1
             b    2
        two  a    3
             b    4
        dtype: int64

        >>> s.unstack(level=-1)
             a  b
        one  1  2
        two  3  4

        >>> s.unstack(level=0)
           one  two
        a    1    3
        b    2    4

        Returns
        -------
        unstacked : DataFrame
        """
        ...
    
    def map(self, arg, na_action: Optional[Any] = ...):
        """
        Map values of Series using input correspondence (which can be
        a dict, Series, or function)

        Parameters
        ----------
        arg : function, dict, or Series
        na_action : {None, 'ignore'}
            If 'ignore', propagate NA values, without passing them to the
            mapping function

        Returns
        -------
        y : Series
            same index as caller

        Examples
        --------

        Map inputs to outputs (both of type `Series`)

        >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])
        >>> x
        one      1
        two      2
        three    3
        dtype: int64

        >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])
        >>> y
        1    foo
        2    bar
        3    baz

        >>> x.map(y)
        one   foo
        two   bar
        three baz

        If `arg` is a dictionary, return a new Series with values converted
        according to the dictionary's mapping:

        >>> z = {1: 'A', 2: 'B', 3: 'C'}

        >>> x.map(z)
        one   A
        two   B
        three C

        Use na_action to control whether NA values are affected by the mapping
        function.

        >>> s = pd.Series([1, 2, 3, np.nan])

        >>> s2 = s.map('this is a string {}'.format, na_action=None)
        0    this is a string 1.0
        1    this is a string 2.0
        2    this is a string 3.0
        3    this is a string nan
        dtype: object

        >>> s3 = s.map('this is a string {}'.format, na_action='ignore')
        0    this is a string 1.0
        1    this is a string 2.0
        2    this is a string 3.0
        3                     NaN
        dtype: object

        See Also
        --------
        Series.apply: For applying more complex functions on a Series
        DataFrame.apply: Apply a function row-/column-wise
        DataFrame.applymap: Apply a function elementwise on a whole DataFrame

        Notes
        -----
        When `arg` is a dictionary, values in Series that are not in the
        dictionary (as keys) are converted to ``NaN``. However, if the
        dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.
        provides a method for default values), then this default is used
        rather than ``NaN``:

        >>> from collections import Counter
        >>> counter = Counter()
        >>> counter['bar'] += 1
        >>> y.map(counter)
        1    0
        2    1
        3    0
        dtype: int64
        """
        ...
    
    def _gotitem(self, key, ndim, subset: Optional[Any] = ...):
        """
        sub-classes to define
        return a sliced object

        Parameters
        ----------
        key : string / list of selections
        ndim : 1,2
            requested ndim of result
        subset : object, default None
            subset to act on
        """
        ...
    
    _agg_doc = ...
    @Appender(_agg_doc)
    @Appender(generic._shared_docs['aggregate'] % dict(versionadded='.. versionadded:: 0.20.0', **_shared_doc_kwargs))
    def aggregate(self, func, axis=..., *args, **kwargs):
        ...
    
    agg = ...
    def apply(self, func, convert_dtype: bool = ..., args=..., **kwds):
        """
        Invoke function on values of Series. Can be ufunc (a NumPy function
        that applies to the entire Series) or a Python function that only works
        on single values

        Parameters
        ----------
        func : function
        convert_dtype : boolean, default True
            Try to find better dtype for elementwise function results. If
            False, leave as dtype=object
        args : tuple
            Positional arguments to pass to function in addition to the value
        Additional keyword arguments will be passed as keywords to the function

        Returns
        -------
        y : Series or DataFrame if func returns a Series

        See also
        --------
        Series.map: For element-wise operations
        Series.agg: only perform aggregating type operations
        Series.transform: only perform transformating type operations

        Examples
        --------

        Create a series with typical summer temperatures for each city.

        >>> import pandas as pd
        >>> import numpy as np
        >>> series = pd.Series([20, 21, 12], index=['London',
        ... 'New York','Helsinki'])
        >>> series
        London      20
        New York    21
        Helsinki    12
        dtype: int64

        Square the values by defining a function and passing it as an
        argument to ``apply()``.

        >>> def square(x):
        ...     return x**2
        >>> series.apply(square)
        London      400
        New York    441
        Helsinki    144
        dtype: int64

        Square the values by passing an anonymous function as an
        argument to ``apply()``.

        >>> series.apply(lambda x: x**2)
        London      400
        New York    441
        Helsinki    144
        dtype: int64

        Define a custom function that needs additional positional
        arguments and pass these additional arguments using the
        ``args`` keyword.

        >>> def subtract_custom_value(x, custom_value):
        ...     return x-custom_value

        >>> series.apply(subtract_custom_value, args=(5,))
        London      15
        New York    16
        Helsinki     7
        dtype: int64

        Define a custom function that takes keyword arguments
        and pass these arguments to ``apply``.

        >>> def add_custom_values(x, **kwargs):
        ...     for month in kwargs:
        ...         x+=kwargs[month]
        ...         return x

        >>> series.apply(add_custom_values, june=30, july=20, august=25)
        London      95
        New York    96
        Helsinki    87
        dtype: int64

        Use a function from the Numpy library.

        >>> series.apply(np.log)
        London      2.995732
        New York    3.044522
        Helsinki    2.484907
        dtype: float64


        """
        ...
    
    def _reduce(self, op, name, axis=..., skipna: bool = ..., numeric_only: Optional[Any] = ..., filter_type: Optional[Any] = ..., **kwds):
        """
        perform a reduction operation

        if we have an ndarray as a value, then simply perform the operation,
        otherwise delegate to the object

        """
        ...
    
    def _reindex_indexer(self, new_index, indexer, copy):
        ...
    
    def _needs_reindex_multi(self, axes, method, level):
        """ check if we do need a multi reindex; this is for compat with
        higher dims
        """
        ...
    
    @Appender(generic._shared_docs['align'] % _shared_doc_kwargs)
    def align(self, other, join=..., axis: Optional[Any] = ..., level: Optional[Any] = ..., copy: bool = ..., fill_value: Optional[Any] = ..., method: Optional[Any] = ..., limit: Optional[Any] = ..., fill_axis=..., broadcast_axis: Optional[Any] = ...):
        ...
    
    def rename(self, index: Optional[Any] = ..., **kwargs):
        """Alter Series index labels or name

        Function / dict values must be unique (1-to-1). Labels not contained in
        a dict / Series will be left as-is. Extra labels listed don't throw an
        error.

        Alternatively, change ``Series.name`` with a scalar value.

        See the :ref:`user guide <basics.rename>` for more.

        Parameters
        ----------
        index : scalar, hashable sequence, dict-like or function, optional
            dict-like or functions are transformations to apply to
            the index.
            Scalar or hashable sequence-like will alter the ``Series.name``
            attribute.
        copy : boolean, default True
            Also copy underlying data
        inplace : boolean, default False
            Whether to return a new %(klass)s. If True then value of copy is
            ignored.
        level : int or level name, default None
            In case of a MultiIndex, only rename labels in the specified
            level.

        Returns
        -------
        renamed : Series (new object)

        See Also
        --------
        pandas.Series.rename_axis

        Examples
        --------

        >>> s = pd.Series([1, 2, 3])
        >>> s
        0    1
        1    2
        2    3
        dtype: int64
        >>> s.rename("my_name") # scalar, changes Series.name
        0    1
        1    2
        2    3
        Name: my_name, dtype: int64
        >>> s.rename(lambda x: x ** 2)  # function, changes labels
        0    1
        1    2
        4    3
        dtype: int64
        >>> s.rename({1: 3, 2: 5})  # mapping, changes labels
        0    1
        3    2
        5    3
        dtype: int64

        """
        ...
    
    @Appender(generic._shared_docs['reindex'] % _shared_doc_kwargs)
    def reindex(self, index: Optional[Any] = ..., **kwargs):
        ...
    
    @Appender(generic._shared_docs['fillna'] % _shared_doc_kwargs)
    def fillna(self, value: Optional[Any] = ..., method: Optional[Any] = ..., axis: Optional[Any] = ..., inplace: bool = ..., limit: Optional[Any] = ..., downcast: Optional[Any] = ..., **kwargs):
        ...
    
    @Appender(generic._shared_docs['shift'] % _shared_doc_kwargs)
    def shift(self, periods=..., freq: Optional[Any] = ..., axis=...):
        ...
    
    def reindex_axis(self, labels, axis=..., **kwargs):
        """ for compatibility with higher dims """
        ...
    
    def memory_usage(self, index: bool = ..., deep: bool = ...):
        """Memory usage of the Series

        Parameters
        ----------
        index : bool
            Specifies whether to include memory usage of Series index
        deep : bool
            Introspect the data deeply, interrogate
            `object` dtypes for system-level memory consumption

        Returns
        -------
        scalar bytes of memory consumed

        Notes
        -----
        Memory usage does not include memory consumed by elements that
        are not components of the array if deep=False

        See Also
        --------
        numpy.ndarray.nbytes
        """
        ...
    
    @Appender(generic._shared_docs['_take'])
    def _take(self, indices, axis=..., convert: bool = ..., is_copy: bool = ...):
        ...
    
    def isin(self, values):
        """
        Return a boolean :class:`~pandas.Series` showing whether each element
        in the :class:`~pandas.Series` is exactly contained in the passed
        sequence of ``values``.

        Parameters
        ----------
        values : set or list-like
            The sequence of values to test. Passing in a single string will
            raise a ``TypeError``. Instead, turn a single string into a
            ``list`` of one element.

            .. versionadded:: 0.18.1

            Support for values as a set

        Returns
        -------
        isin : Series (bool dtype)

        Raises
        ------
        TypeError
          * If ``values`` is a string

        See Also
        --------
        pandas.DataFrame.isin

        Examples
        --------

        >>> s = pd.Series(list('abc'))
        >>> s.isin(['a', 'c', 'e'])
        0     True
        1    False
        2     True
        dtype: bool

        Passing a single string as ``s.isin('a')`` will raise an error. Use
        a list of one element instead:

        >>> s.isin(['a'])
        0     True
        1    False
        2    False
        dtype: bool

        """
        ...
    
    def between(self, left, right, inclusive: bool = ...):
        """
        Return boolean Series equivalent to left <= series <= right. NA values
        will be treated as False

        Parameters
        ----------
        left : scalar
            Left boundary
        right : scalar
            Right boundary

        Returns
        -------
        is_between : Series
        """
        ...
    
    @classmethod
    def from_csv(cls, path, sep=..., parse_dates: bool = ..., header: Optional[Any] = ..., index_col=..., encoding: Optional[Any] = ..., infer_datetime_format: bool = ...):
        """
        Read CSV file (DEPRECATED, please use :func:`pandas.read_csv`
        instead).

        It is preferable to use the more powerful :func:`pandas.read_csv`
        for most general purposes, but ``from_csv`` makes for an easy
        roundtrip to and from a file (the exact counterpart of
        ``to_csv``), especially with a time Series.

        This method only differs from :func:`pandas.read_csv` in some defaults:

        - `index_col` is ``0`` instead of ``None`` (take first column as index
          by default)
        - `header` is ``None`` instead of ``0`` (the first row is not used as
          the column names)
        - `parse_dates` is ``True`` instead of ``False`` (try parsing the index
          as datetime by default)

        With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used
        to return a Series like ``from_csv``.

        Parameters
        ----------
        path : string file path or file handle / StringIO
        sep : string, default ','
            Field delimiter
        parse_dates : boolean, default True
            Parse dates. Different default from read_table
        header : int, default None
            Row to use as header (skip prior rows)
        index_col : int or sequence, default 0
            Column to use for index. If a sequence is given, a MultiIndex
            is used. Different default from read_table
        encoding : string, optional
            a string representing the encoding to use if the contents are
            non-ascii, for python versions prior to 3
        infer_datetime_format: boolean, default False
            If True and `parse_dates` is True for a column, try to infer the
            datetime format based on the first datetime string. If the format
            can be inferred, there often will be a large parsing speed-up.

        See also
        --------
        pandas.read_csv

        Returns
        -------
        y : Series
        """
        ...
    
    def to_csv(self, path: Optional[Any] = ..., index: bool = ..., sep=..., na_rep=..., float_format: Optional[Any] = ..., header: bool = ..., index_label: Optional[Any] = ..., mode=..., encoding: Optional[Any] = ..., date_format: Optional[Any] = ..., decimal=...):
        """
        Write Series to a comma-separated values (csv) file

        Parameters
        ----------
        path : string or file handle, default None
            File path or object, if None is provided the result is returned as
            a string.
        na_rep : string, default ''
            Missing data representation
        float_format : string, default None
            Format string for floating point numbers
        header : boolean, default False
            Write out series name
        index : boolean, default True
            Write row names (index)
        index_label : string or sequence, default None
            Column label for index column(s) if desired. If None is given, and
            `header` and `index` are True, then the index names are used. A
            sequence should be given if the DataFrame uses MultiIndex.
        mode : Python write mode, default 'w'
        sep : character, default ","
            Field delimiter for the output file.
        encoding : string, optional
            a string representing the encoding to use if the contents are
            non-ascii, for python versions prior to 3
        date_format: string, default None
            Format string for datetime objects.
        decimal: string, default '.'
            Character recognized as decimal separator. E.g. use ',' for
            European data
        """
        ...
    
    @Appender(generic._shared_docs['to_excel'] % _shared_doc_kwargs)
    def to_excel(self, excel_writer, sheet_name=..., na_rep=..., float_format: Optional[Any] = ..., columns: Optional[Any] = ..., header: bool = ..., index: bool = ..., index_label: Optional[Any] = ..., startrow=..., startcol=..., engine: Optional[Any] = ..., merge_cells: bool = ..., encoding: Optional[Any] = ..., inf_rep=..., verbose: bool = ...):
        ...
    
    @Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)
    def isna(self):
        ...
    
    @Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)
    def isnull(self):
        ...
    
    @Appender(generic._shared_docs['notna'] % _shared_doc_kwargs)
    def notna(self):
        ...
    
    @Appender(generic._shared_docs['notna'] % _shared_doc_kwargs)
    def notnull(self):
        ...
    
    def dropna(self, axis=..., inplace: bool = ..., **kwargs):
        """
        Return Series without null values

        Returns
        -------
        valid : Series
        inplace : boolean, default False
            Do operation in place.
        """
        ...
    
    valid = ...
    @Appender(generic._shared_docs['valid_index'] % { 'position': 'first','klass': 'Series' })
    def first_valid_index(self):
        ...
    
    @Appender(generic._shared_docs['valid_index'] % { 'position': 'last','klass': 'Series' })
    def last_valid_index(self):
        ...
    
    def to_timestamp(self, freq: Optional[Any] = ..., how=..., copy: bool = ...):
        """
        Cast to datetimeindex of timestamps, at *beginning* of period

        Parameters
        ----------
        freq : string, default frequency of PeriodIndex
            Desired frequency
        how : {'s', 'e', 'start', 'end'}
            Convention for converting period to timestamp; start of period
            vs. end

        Returns
        -------
        ts : Series with DatetimeIndex
        """
        ...
    
    def to_period(self, freq: Optional[Any] = ..., copy: bool = ...):
        """
        Convert Series from DatetimeIndex to PeriodIndex with desired
        frequency (inferred from index if not passed)

        Parameters
        ----------
        freq : string, default

        Returns
        -------
        ts : Series with PeriodIndex
        """
        ...
    
    dt = ...
    cat = ...
    str = ...
    plot = ...
    hist = ...


def _sanitize_index(data, index, copy: bool = ...):
    """ sanitize an index type to return an ndarray of the underlying, pass
    thru a non-Index
    """
    ...

def _sanitize_array(data, index, dtype: Optional[Any] = ..., copy: bool = ..., raise_cast_failure: bool = ...):
    """ sanitize input data to an ndarray, copy if specified, coerce to the
    dtype if specified
    """
    ...

