"""
This type stub file was generated by pyright.
"""

import pandas.core.generic as generic
from pandas.core.frame import DataFrame
from pandas.util._decorators import Appender
from typing import Any, Optional

"""
Data structures for sparse float data. Life is made simpler by dealing only
with float64 data
"""
_shared_doc_kwargs = dict(klass='SparseDataFrame')
class SparseDataFrame(DataFrame):
    """
    DataFrame containing sparse floating point data in the form of SparseSeries
    objects

    Parameters
    ----------
    data : same types as can be passed to DataFrame or scipy.sparse.spmatrix
    index : array-like, optional
    column : array-like, optional
    default_kind : {'block', 'integer'}, default 'block'
        Default sparse kind for converting Series to SparseSeries. Will not
        override SparseSeries passed into constructor
    default_fill_value : float
        Default fill_value for converting Series to SparseSeries
        (default: nan). Will not override SparseSeries passed in.
    """
    _subtyp = ...
    def __init__(self, data: Optional[Any] = ..., index: Optional[Any] = ..., columns: Optional[Any] = ..., default_kind: Optional[Any] = ..., default_fill_value: Optional[Any] = ..., dtype: Optional[Any] = ..., copy: bool = ...):
        ...
    
    @property
    def _constructor(self):
        ...
    
    _constructor_sliced = ...
    def _init_dict(self, data, index, columns, dtype: Optional[Any] = ...):
        ...
    
    def _init_matrix(self, data, index, columns, dtype: Optional[Any] = ...):
        """ Init self from ndarray or list of lists """
        ...
    
    def _init_spmatrix(self, data, index, columns, dtype: Optional[Any] = ..., fill_value: Optional[Any] = ...):
        """ Init self from scipy.sparse matrix """
        ...
    
    def _prep_index(self, data, index, columns):
        ...
    
    def to_coo(self):
        """
        Return the contents of the frame as a sparse SciPy COO matrix.

        .. versionadded:: 0.20.0

        Returns
        -------
        coo_matrix : scipy.sparse.spmatrix
            If the caller is heterogeneous and contains booleans or objects,
            the result will be of dtype=object. See Notes.

        Notes
        -----
        The dtype will be the lowest-common-denominator type (implicit
        upcasting); that is to say if the dtypes (even of numeric types)
        are mixed, the one that accommodates all will be chosen.

        e.g. If the dtypes are float16 and float32, dtype will be upcast to
        float32. By numpy.find_common_type convention, mixing int64 and
        and uint64 will result in a float64 dtype.
        """
        ...
    
    def __array_wrap__(self, result):
        ...
    
    def __getstate__(self):
        ...
    
    def _unpickle_sparse_frame_compat(self, state):
        """ original pickle format """
        ...
    
    def to_dense(self):
        """
        Convert to dense DataFrame

        Returns
        -------
        df : DataFrame
        """
        ...
    
    def _apply_columns(self, func):
        """ get new SparseDataFrame applying func to each columns """
        ...
    
    def astype(self, dtype):
        ...
    
    def copy(self, deep: bool = ...):
        """
        Make a copy of this SparseDataFrame
        """
        ...
    
    @property
    def default_fill_value(self):
        ...
    
    @property
    def default_kind(self):
        ...
    
    @property
    def density(self):
        """
        Ratio of non-sparse points to total (dense) data points
        represented in the frame
        """
        ...
    
    def fillna(self, value: Optional[Any] = ..., method: Optional[Any] = ..., axis=..., inplace: bool = ..., limit: Optional[Any] = ..., downcast: Optional[Any] = ...):
        ...
    
    def _sanitize_column(self, key, value, **kwargs):
        """
        Creates a new SparseArray from the input value.

        Parameters
        ----------
        key : object
        value : scalar, Series, or array-like
        kwargs : dict

        Returns
        -------
        sanitized_column : SparseArray

        """
        ...
    
    def __getitem__(self, key):
        """
        Retrieve column or slice from DataFrame
        """
        ...
    
    def get_value(self, index, col, takeable: bool = ...):
        """
        Quickly retrieve single value at passed column and index

        .. deprecated:: 0.21.0

        Please use .at[] or .iat[] accessors.

        Parameters
        ----------
        index : row label
        col : column label
        takeable : interpret the index/col as indexers, default False

        Returns
        -------
        value : scalar value
        """
        ...
    
    def _get_value(self, index, col, takeable: bool = ...):
        ...
    
    def set_value(self, index, col, value, takeable: bool = ...):
        """
        Put single value at passed column and index

        .. deprecated:: 0.21.0

        Please use .at[] or .iat[] accessors.

        Parameters
        ----------
        index : row label
        col : column label
        value : scalar value
        takeable : interpret the index/col as indexers, default False

        Notes
        -----
        This method *always* returns a new object. It is currently not
        particularly efficient (and potentially very expensive) but is provided
        for API compatibility with DataFrame

        Returns
        -------
        frame : DataFrame
        """
        ...
    
    def _set_value(self, index, col, value, takeable: bool = ...):
        ...
    
    def _slice(self, slobj, axis=..., kind: Optional[Any] = ...):
        ...
    
    def xs(self, key, axis=..., copy: bool = ...):
        """
        Returns a row (cross-section) from the SparseDataFrame as a Series
        object.

        Parameters
        ----------
        key : some index contained in the index

        Returns
        -------
        xs : Series
        """
        ...
    
    def _combine_frame(self, other, func, fill_value: Optional[Any] = ..., level: Optional[Any] = ..., try_cast: bool = ...):
        ...
    
    def _combine_match_index(self, other, func, level: Optional[Any] = ..., fill_value: Optional[Any] = ..., try_cast: bool = ...):
        ...
    
    def _combine_match_columns(self, other, func, level: Optional[Any] = ..., fill_value: Optional[Any] = ..., try_cast: bool = ...):
        ...
    
    def _combine_const(self, other, func, errors=..., try_cast: bool = ...):
        ...
    
    def _reindex_index(self, index, method, copy, level, fill_value=..., limit: Optional[Any] = ..., takeable: bool = ...):
        ...
    
    def _reindex_columns(self, columns, method, copy, level, fill_value: Optional[Any] = ..., limit: Optional[Any] = ..., takeable: bool = ...):
        ...
    
    def _reindex_with_indexers(self, reindexers, method: Optional[Any] = ..., fill_value: Optional[Any] = ..., limit: Optional[Any] = ..., copy: bool = ..., allow_dups: bool = ...):
        ...
    
    def _join_compat(self, other, on: Optional[Any] = ..., how=..., lsuffix=..., rsuffix=..., sort: bool = ...):
        ...
    
    def _join_index(self, other, how, lsuffix, rsuffix):
        ...
    
    def _maybe_rename_join(self, other, lsuffix, rsuffix):
        ...
    
    def transpose(self, *args, **kwargs):
        """
        Returns a DataFrame with the rows/columns switched.
        """
        ...
    
    T = ...
    @Appender(DataFrame.count.__doc__)
    def count(self, axis=..., **kwds):
        ...
    
    def cumsum(self, axis=..., *args, **kwargs):
        """
        Return SparseDataFrame of cumulative sums over requested axis.

        Parameters
        ----------
        axis : {0, 1}
            0 for row-wise, 1 for column-wise

        Returns
        -------
        y : SparseDataFrame
        """
        ...
    
    @Appender(generic._shared_docs['isna'])
    def isna(self):
        ...
    
    isnull = ...
    @Appender(generic._shared_docs['notna'])
    def notna(self):
        ...
    
    notnull = ...
    def apply(self, func, axis=..., broadcast: bool = ..., reduce: bool = ...):
        """
        Analogous to DataFrame.apply, for SparseDataFrame

        Parameters
        ----------
        func : function
            Function to apply to each column
        axis : {0, 1, 'index', 'columns'}
        broadcast : bool, default False
            For aggregation functions, return object of same size with values
            propagated

        Returns
        -------
        applied : Series or SparseDataFrame
        """
        ...
    
    def applymap(self, func):
        """
        Apply a function to a DataFrame that is intended to operate
        elementwise, i.e. like doing map(func, series) for each series in the
        DataFrame

        Parameters
        ----------
        func : function
            Python function, returns a single value from a single value

        Returns
        -------
        applied : DataFrame
        """
        ...
    


def to_manager(sdf, columns, index):
    """ create and return the block manager from a dataframe of series,
    columns, index
    """
    ...

def stack_sparse_frame(frame):
    """
    Only makes sense when fill_value is NaN
    """
    ...

def homogenize(series_dict):
    """
    Conform a set of SparseSeries (with NaN fill_value) to a common SparseIndex
    corresponding to the locations where they all have data

    Parameters
    ----------
    series_dict : dict or DataFrame

    Notes
    -----
    Using the dumbest algorithm I could think of. Should put some more thought
    into this

    Returns
    -------
    homogenized : dict of SparseSeries
    """
    ...

