"""
This type stub file was generated by pyright.
"""

import string
import sys
import numpy as np
import pandas as pd
import pandas.compat as compat
from functools import partial
from contextlib import contextmanager
from pandas.compat import httplib, lrange, map, u, unichr
from pandas import Categorical, DataFrame, Series
from typing import Any, Optional

N = 30
K = 4
_RAISE_NETWORK_ERROR_DEFAULT = False
_testing_mode_warnings = (DeprecationWarning, compat.ResourceWarning)
def set_testing_mode():
    ...

def reset_testing_mode():
    ...

def reset_display_options():
    """
    Reset the display options for printing and representing objects.
    """
    ...

def round_trip_pickle(obj, path: Optional[Any] = ...):
    """
    Pickle an object and then read it again.

    Parameters
    ----------
    obj : pandas object
        The object to pickle and then re-read.
    path : str, default None
        The path where the pickled object is written and then read.

    Returns
    -------
    round_trip_pickled_object : pandas object
        The original object that was pickled and then re-read.
    """
    ...

def round_trip_pathlib(writer, reader, path: Optional[Any] = ...):
    """
    Write an object to file specifed by a pathlib.Path and read it back

    Parameters
    ----------
    writer : callable bound to pandas object
        IO writing function (e.g. DataFrame.to_csv )
    reader : callable
        IO reading function (e.g. pd.read_csv )
    path : str, default None
        The path where the object is written and then read.

    Returns
    -------
    round_trip_object : pandas object
        The original object that was serialized and then re-read.
    """
    ...

def round_trip_localpath(writer, reader, path: Optional[Any] = ...):
    """
    Write an object to file specifed by a py.path LocalPath and read it back

    Parameters
    ----------
    writer : callable bound to pandas object
        IO writing function (e.g. DataFrame.to_csv )
    reader : callable
        IO reading function (e.g. pd.read_csv )
    path : str, default None
        The path where the object is written and then read.

    Returns
    -------
    round_trip_object : pandas object
        The original object that was serialized and then re-read.
    """
    ...

def assert_almost_equal(left, right, check_exact: bool = ..., check_dtype=..., check_less_precise: bool = ..., **kwargs):
    """
    Check that the left and right objects are approximately equal.

    Parameters
    ----------
    left : object
    right : object
    check_exact : bool, default False
        Whether to compare number exactly.
    check_dtype: bool, default True
        check dtype if both a and b are the same type
    check_less_precise : bool or int, default False
        Specify comparison precision. Only used when check_exact is False.
        5 digits (False) or 3 digits (True) after decimal points are compared.
        If int, then specify the digits to compare
    """
    ...

def _check_isinstance(left, right, cls):
    """
    Helper method for our assert_* methods that ensures that
    the two objects being compared have the right type before
    proceeding with the comparison.

    Parameters
    ----------
    left : The first object being compared.
    right : The second object being compared.
    cls : The class type to check against.

    Raises
    ------
    AssertionError : Either `left` or `right` is not an instance of `cls`.
    """
    ...

def assert_dict_equal(left, right, compare_keys: bool = ...):
    ...

def randbool(size=..., p=...):
    ...

RANDS_CHARS = np.array(list(string.ascii_letters + string.digits), dtype=(np.str_, 1))
RANDU_CHARS = np.array(list(u("").join(map(unichr, lrange(1488, 1488 + 26))) + string.digits), dtype=(np.unicode_, 1))
def rands_array(nchars, size, dtype=...):
    """Generate an array of byte strings."""
    ...

def randu_array(nchars, size, dtype=...):
    """Generate an array of unicode strings."""
    ...

def rands(nchars):
    """
    Generate one random byte string.

    See `rands_array` if you want to create an array of random strings.

    """
    ...

def randu(nchars):
    """
    Generate one random unicode string.

    See `randu_array` if you want to create an array of random unicode strings.

    """
    ...

def close(fignum: Optional[Any] = ...):
    ...

def _skip_if_32bit():
    ...

def _skip_if_no_mpl():
    ...

def _skip_if_mpl_1_5():
    ...

def _skip_if_no_scipy():
    ...

def _check_if_lzma():
    ...

def _skip_if_no_lzma():
    ...

def _skip_if_no_xarray():
    ...

def _skip_if_windows_python_3():
    ...

def _skip_if_windows():
    ...

def _skip_if_no_pathlib():
    ...

def _skip_if_no_localpath():
    ...

def skip_if_no_ne(engine=...):
    ...

def _skip_if_has_locale():
    ...

def _skip_if_not_us_locale():
    ...

def _skip_if_no_mock():
    ...

def _skip_if_no_ipython():
    ...

def check_output(*popenargs, **kwargs):
    r"""Run command with arguments and return its output as a byte string.

    If the exit code was non-zero it raises a CalledProcessError.  The
    CalledProcessError object will have the return code in the returncode
    attribute and output in the output attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> check_output(["ls", "-l", "/dev/null"])
    'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\n'

    The stdout argument is not allowed as it is used internally.
    To capture standard error in the result, use stderr=STDOUT.

    >>> check_output(["/bin/sh", "-c",
    ...               "ls -l non_existent_file ; exit 0"],
    ...              stderr=STDOUT)
    'ls: non_existent_file: No such file or directory\n'
    """
    ...

def _default_locale_getter():
    ...

def get_locales(prefix: Optional[Any] = ..., normalize: bool = ..., locale_getter=...):
    """Get all the locales that are available on the system.

    Parameters
    ----------
    prefix : str
        If not ``None`` then return only those locales with the prefix
        provided. For example to get all English language locales (those that
        start with ``"en"``), pass ``prefix="en"``.
    normalize : bool
        Call ``locale.normalize`` on the resulting list of available locales.
        If ``True``, only locales that can be set without throwing an
        ``Exception`` are returned.
    locale_getter : callable
        The function to use to retrieve the current locales. This should return
        a string with each locale separated by a newline character.

    Returns
    -------
    locales : list of strings
        A list of locale strings that can be set with ``locale.setlocale()``.
        For example::

            locale.setlocale(locale.LC_ALL, locale_string)

    On error will return None (no locale available, e.g. Windows)

    """
    ...

@contextmanager
def set_locale(new_locale, lc_var=...):
    """Context manager for temporarily setting a locale.

    Parameters
    ----------
    new_locale : str or tuple
        A string of the form <language_country>.<encoding>. For example to set
        the current locale to US English with a UTF8 encoding, you would pass
        "en_US.UTF-8".

    Notes
    -----
    This is useful when you want to run a particular block of code under a
    particular locale, without globally setting the locale. This probably isn't
    thread-safe.
    """
    ...

def _can_set_locale(lc):
    """Check to see if we can set a locale without throwing an exception.

    Parameters
    ----------
    lc : str
        The locale to attempt to set.

    Returns
    -------
    isvalid : bool
        Whether the passed locale can be set
    """
    ...

def _valid_locales(locales, normalize):
    """Return a list of normalized locales that do not throw an ``Exception``
    when set.

    Parameters
    ----------
    locales : str
        A string where each locale is separated by a newline.
    normalize : bool
        Whether to call ``locale.normalize`` on each locale.

    Returns
    -------
    valid_locales : list
        A list of valid locales.
    """
    ...

def capture_stdout(f):
    """
    Decorator to capture stdout in a buffer so that it can be checked
    (or suppressed) during testing.

    Parameters
    ----------
    f : callable
        The test that is capturing stdout.

    Returns
    -------
    f : callable
        The decorated test ``f``, which captures stdout.

    Examples
    --------

    >>> from pandas.util.testing import capture_stdout
    >>>
    >>> import sys
    >>>
    >>> @capture_stdout
    ... def test_print_pass():
    ...     print("foo")
    ...     out = sys.stdout.getvalue()
    ...     assert out == "foo\n"
    >>>
    >>> @capture_stdout
    ... def test_print_fail():
    ...     print("foo")
    ...     out = sys.stdout.getvalue()
    ...     assert out == "bar\n"
    ...
    AssertionError: assert 'foo\n' == 'bar\n'
    """
    ...

def capture_stderr(f):
    """
    Decorator to capture stderr in a buffer so that it can be checked
    (or suppressed) during testing.

    Parameters
    ----------
    f : callable
        The test that is capturing stderr.

    Returns
    -------
    f : callable
        The decorated test ``f``, which captures stderr.

    Examples
    --------

    >>> from pandas.util.testing import capture_stderr
    >>>
    >>> import sys
    >>>
    >>> @capture_stderr
    ... def test_stderr_pass():
    ...     sys.stderr.write("foo")
    ...     out = sys.stderr.getvalue()
    ...     assert out == "foo\n"
    >>>
    >>> @capture_stderr
    ... def test_stderr_fail():
    ...     sys.stderr.write("foo")
    ...     out = sys.stderr.getvalue()
    ...     assert out == "bar\n"
    ...
    AssertionError: assert 'foo\n' == 'bar\n'
    """
    ...

def debug(f, *args, **kwargs):
    ...

def pudebug(f, *args, **kwargs):
    ...

def set_trace():
    ...

@contextmanager
def ensure_clean(filename: Optional[Any] = ..., return_filelike: bool = ...):
    """Gets a temporary path and agrees to remove on close.

    Parameters
    ----------
    filename : str (optional)
        if None, creates a temporary file which is then removed when out of
        scope. if passed, creates temporary file with filename as ending.
    return_filelike : bool (default False)
        if True, returns a file-like which is *always* cleaned. Necessary for
        savefig and other functions which want to append extensions.
    """
    ...

def get_data_path(f=...):
    """Return the path of a data file, these are relative to the current test
    directory.
    """
    ...

def equalContents(arr1, arr2):
    """Checks if the set of unique elements of arr1 and arr2 are equivalent.
    """
    ...

def assert_index_equal(left, right, exact=..., check_names: bool = ..., check_less_precise: bool = ..., check_exact: bool = ..., check_categorical: bool = ..., obj=...):
    """Check that left and right Index are equal.

    Parameters
    ----------
    left : Index
    right : Index
    exact : bool / string {'equiv'}, default False
        Whether to check the Index class, dtype and inferred_type
        are identical. If 'equiv', then RangeIndex can be substituted for
        Int64Index as well.
    check_names : bool, default True
        Whether to check the names attribute.
    check_less_precise : bool or int, default False
        Specify comparison precision. Only used when check_exact is False.
        5 digits (False) or 3 digits (True) after decimal points are compared.
        If int, then specify the digits to compare
    check_exact : bool, default True
        Whether to compare number exactly.
    check_categorical : bool, default True
        Whether to compare internal Categorical exactly.
    obj : str, default 'Index'
        Specify object name being compared, internally used to show appropriate
        assertion message
    """
    ...

def assert_class_equal(left, right, exact: bool = ..., obj=...):
    """checks classes are equal."""
    ...

def assert_attr_equal(attr, left, right, obj=...):
    """checks attributes are equal. Both objects must have attribute.

    Parameters
    ----------
    attr : str
        Attribute name being compared.
    left : object
    right : object
    obj : str, default 'Attributes'
        Specify object name being compared, internally used to show appropriate
        assertion message
    """
    ...

def assert_is_valid_plot_return_object(objs):
    ...

def isiterable(obj):
    ...

def is_sorted(seq):
    ...

def assert_categorical_equal(left, right, check_dtype: bool = ..., obj=..., check_category_order: bool = ...):
    """Test that Categoricals are equivalent.

    Parameters
    ----------
    left, right : Categorical
        Categoricals to compare
    check_dtype : bool, default True
        Check that integer dtype of the codes are the same
    obj : str, default 'Categorical'
        Specify object name being compared, internally used to show appropriate
        assertion message
    check_category_order : bool, default True
        Whether the order of the categories should be compared, which
        implies identical integer codes.  If False, only the resulting
        values are compared.  The ordered attribute is
        checked regardless.
    """
    ...

def raise_assert_detail(obj, message, left, right, diff: Optional[Any] = ...):
    ...

def assert_numpy_array_equal(left, right, strict_nan: bool = ..., check_dtype: bool = ..., err_msg: Optional[Any] = ..., obj=..., check_same: Optional[Any] = ...):
    """ Checks that 'np.ndarray' is equivalent

    Parameters
    ----------
    left : np.ndarray or iterable
    right : np.ndarray or iterable
    strict_nan : bool, default False
        If True, consider NaN and None to be different.
    check_dtype: bool, default True
        check dtype if both a and b are np.ndarray
    err_msg : str, default None
        If provided, used as assertion message
    obj : str, default 'numpy array'
        Specify object name being compared, internally used to show appropriate
        assertion message
    check_same : None|'copy'|'same', default None
        Ensure left and right refer/do not refer to the same memory area
    """
    ...

def assert_series_equal(left, right, check_dtype: bool = ..., check_index_type=..., check_series_type: bool = ..., check_less_precise: bool = ..., check_names: bool = ..., check_exact: bool = ..., check_datetimelike_compat: bool = ..., check_categorical: bool = ..., obj=...):
    """Check that left and right Series are equal.

    Parameters
    ----------
    left : Series
    right : Series
    check_dtype : bool, default True
        Whether to check the Series dtype is identical.
    check_index_type : bool / string {'equiv'}, default 'equiv'
        Whether to check the Index class, dtype and inferred_type
        are identical.
    check_series_type : bool, default True
        Whether to check the Series class is identical.
    check_less_precise : bool or int, default False
        Specify comparison precision. Only used when check_exact is False.
        5 digits (False) or 3 digits (True) after decimal points are compared.
        If int, then specify the digits to compare
    check_exact : bool, default False
        Whether to compare number exactly.
    check_names : bool, default True
        Whether to check the Series and Index names attribute.
    check_datetimelike_compat : bool, default False
        Compare datetime-like which is comparable ignoring dtype.
    check_categorical : bool, default True
        Whether to compare internal Categorical exactly.
    obj : str, default 'Series'
        Specify object name being compared, internally used to show appropriate
        assertion message
    """
    ...

def assert_frame_equal(left, right, check_dtype: bool = ..., check_index_type=..., check_column_type=..., check_frame_type: bool = ..., check_less_precise: bool = ..., check_names: bool = ..., by_blocks: bool = ..., check_exact: bool = ..., check_datetimelike_compat: bool = ..., check_categorical: bool = ..., check_like: bool = ..., obj=...):
    """Check that left and right DataFrame are equal.

    Parameters
    ----------
    left : DataFrame
    right : DataFrame
    check_dtype : bool, default True
        Whether to check the DataFrame dtype is identical.
    check_index_type : bool / string {'equiv'}, default False
        Whether to check the Index class, dtype and inferred_type
        are identical.
    check_column_type : bool / string {'equiv'}, default False
        Whether to check the columns class, dtype and inferred_type
        are identical.
    check_frame_type : bool, default False
        Whether to check the DataFrame class is identical.
    check_less_precise : bool or int, default False
        Specify comparison precision. Only used when check_exact is False.
        5 digits (False) or 3 digits (True) after decimal points are compared.
        If int, then specify the digits to compare
    check_names : bool, default True
        Whether to check the Index names attribute.
    by_blocks : bool, default False
        Specify how to compare internal data. If False, compare by columns.
        If True, compare by blocks.
    check_exact : bool, default False
        Whether to compare number exactly.
    check_datetimelike_compat : bool, default False
        Compare datetime-like which is comparable ignoring dtype.
    check_categorical : bool, default True
        Whether to compare internal Categorical exactly.
    check_like : bool, default False
        If true, ignore the order of rows & columns
    obj : str, default 'DataFrame'
        Specify object name being compared, internally used to show appropriate
        assertion message
    """
    ...

def assert_panelnd_equal(left, right, check_dtype: bool = ..., check_panel_type: bool = ..., check_less_precise: bool = ..., assert_func=..., check_names: bool = ..., by_blocks: bool = ..., obj=...):
    """Check that left and right Panels are equal.

    Parameters
    ----------
    left : Panel (or nd)
    right : Panel (or nd)
    check_dtype : bool, default True
        Whether to check the Panel dtype is identical.
    check_panel_type : bool, default False
        Whether to check the Panel class is identical.
    check_less_precise : bool or int, default False
        Specify comparison precision. Only used when check_exact is False.
        5 digits (False) or 3 digits (True) after decimal points are compared.
        If int, then specify the digits to compare
    assert_func : function for comparing data
    check_names : bool, default True
        Whether to check the Index names attribute.
    by_blocks : bool, default False
        Specify how to compare internal data. If False, compare by columns.
        If True, compare by blocks.
    obj : str, default 'Panel'
        Specify the object name being compared, internally used to show
        the appropriate assertion message.
    """
    ...

_panel_frame_equal = partial(assert_frame_equal, check_names=False)
assert_panel_equal = partial(assert_panelnd_equal, assert_func=_panel_frame_equal)
assert_panel4d_equal = partial(assert_panelnd_equal, assert_func=assert_panel_equal)
def assert_sp_array_equal(left, right, check_dtype: bool = ...):
    """Check that the left and right SparseArray are equal.

    Parameters
    ----------
    left : SparseArray
    right : SparseArray
    check_dtype : bool, default True
        Whether to check the data dtype is identical.
    """
    ...

def assert_sp_series_equal(left, right, check_dtype: bool = ..., exact_indices: bool = ..., check_series_type: bool = ..., check_names: bool = ..., obj=...):
    """Check that the left and right SparseSeries are equal.

    Parameters
    ----------
    left : SparseSeries
    right : SparseSeries
    check_dtype : bool, default True
        Whether to check the Series dtype is identical.
    exact_indices : bool, default True
    check_series_type : bool, default True
        Whether to check the SparseSeries class is identical.
    check_names : bool, default True
        Whether to check the SparseSeries name attribute.
    obj : str, default 'SparseSeries'
        Specify the object name being compared, internally used to show
        the appropriate assertion message.
    """
    ...

def assert_sp_frame_equal(left, right, check_dtype: bool = ..., exact_indices: bool = ..., check_frame_type: bool = ..., obj=...):
    """Check that the left and right SparseDataFrame are equal.

    Parameters
    ----------
    left : SparseDataFrame
    right : SparseDataFrame
    check_dtype : bool, default True
        Whether to check the Series dtype is identical.
    exact_indices : bool, default True
        SparseSeries SparseIndex objects must be exactly the same,
        otherwise just compare dense representations.
    check_frame_type : bool, default True
        Whether to check the SparseDataFrame class is identical.
    obj : str, default 'SparseDataFrame'
        Specify the object name being compared, internally used to show
        the appropriate assertion message.
    """
    ...

def assert_sp_list_equal(left, right):
    ...

def assert_contains_all(iterable, dic):
    ...

def assert_copy(iter1, iter2, **eql_kwargs):
    """
    iter1, iter2: iterables that produce elements
    comparable with assert_almost_equal

    Checks that the elements are equal, but not
    the same object. (Does not check that items
    in sequences are also not the same object)
    """
    ...

def getCols(k):
    ...

def getArangeMat():
    ...

def makeStringIndex(k=..., name: Optional[Any] = ...):
    ...

def makeUnicodeIndex(k=..., name: Optional[Any] = ...):
    ...

def makeCategoricalIndex(k=..., n=..., name: Optional[Any] = ...):
    """ make a length k index or n categories """
    ...

def makeIntervalIndex(k=..., name: Optional[Any] = ...):
    """ make a length k IntervalIndex """
    ...

def makeBoolIndex(k=..., name: Optional[Any] = ...):
    ...

def makeIntIndex(k=..., name: Optional[Any] = ...):
    ...

def makeUIntIndex(k=..., name: Optional[Any] = ...):
    ...

def makeRangeIndex(k=..., name: Optional[Any] = ...):
    ...

def makeFloatIndex(k=..., name: Optional[Any] = ...):
    ...

def makeDateIndex(k=..., freq=..., name: Optional[Any] = ...):
    ...

def makeTimedeltaIndex(k=..., freq=..., name: Optional[Any] = ...):
    ...

def makePeriodIndex(k=..., name: Optional[Any] = ...):
    ...

def all_index_generator(k=...):
    """Generator which can be iterated over to get instances of all the various
    index classes.

    Parameters
    ----------
    k: length of each of the index instances
    """
    ...

def all_timeseries_index_generator(k=...):
    """Generator which can be iterated over to get instances of all the classes
    which represent time-seires.

    Parameters
    ----------
    k: length of each of the index instances
    """
    ...

def makeFloatSeries(name: Optional[Any] = ...):
    ...

def makeStringSeries(name: Optional[Any] = ...):
    ...

def makeObjectSeries(name: Optional[Any] = ...):
    ...

def getSeriesData():
    ...

def makeTimeSeries(nper: Optional[Any] = ..., freq=..., name: Optional[Any] = ...):
    ...

def makePeriodSeries(nper: Optional[Any] = ..., name: Optional[Any] = ...):
    ...

def getTimeSeriesData(nper: Optional[Any] = ..., freq=...):
    ...

def getPeriodData(nper: Optional[Any] = ...):
    ...

def makeTimeDataFrame(nper: Optional[Any] = ..., freq=...):
    ...

def makeDataFrame():
    ...

def getMixedTypeDict():
    ...

def makeMixedDataFrame():
    ...

def makePeriodFrame(nper: Optional[Any] = ...):
    ...

def makePanel(nper: Optional[Any] = ...):
    ...

def makePeriodPanel(nper: Optional[Any] = ...):
    ...

def makePanel4D(nper: Optional[Any] = ...):
    ...

def makeCustomIndex(nentries, nlevels, prefix=..., names: bool = ..., ndupe_l: Optional[Any] = ..., idx_type: Optional[Any] = ...):
    """Create an index/multindex with given dimensions, levels, names, etc'

    nentries - number of entries in index
    nlevels - number of levels (> 1 produces multindex)
    prefix - a string prefix for labels
    names - (Optional), bool or list of strings. if True will use default
       names, if false will use no names, if a list is given, the name of
       each level in the index will be taken from the list.
    ndupe_l - (Optional), list of ints, the number of rows for which the
       label will repeated at the corresponding level, you can specify just
       the first few, the rest will use the default ndupe_l of 1.
       len(ndupe_l) <= nlevels.
    idx_type - "i"/"f"/"s"/"u"/"dt"/"p"/"td".
       If idx_type is not None, `idx_nlevels` must be 1.
       "i"/"f" creates an integer/float index,
       "s"/"u" creates a string/unicode index
       "dt" create a datetime index.
       "td" create a datetime index.

        if unspecified, string labels will be generated.
    """
    ...

def makeCustomDataframe(nrows, ncols, c_idx_names: bool = ..., r_idx_names: bool = ..., c_idx_nlevels=..., r_idx_nlevels=..., data_gen_f: Optional[Any] = ..., c_ndupe_l: Optional[Any] = ..., r_ndupe_l: Optional[Any] = ..., dtype: Optional[Any] = ..., c_idx_type: Optional[Any] = ..., r_idx_type: Optional[Any] = ...):
    """
   nrows,  ncols - number of data rows/cols
   c_idx_names, idx_names  - False/True/list of strings,  yields No names ,
        default names or  uses the provided names for the levels of the
        corresponding  index. You can provide a single string when
        c_idx_nlevels ==1.
   c_idx_nlevels - number of levels in columns index. > 1 will yield MultiIndex
   r_idx_nlevels - number of levels in rows index. > 1 will yield MultiIndex
   data_gen_f - a function f(row,col) which return the data value
        at that position, the default generator used yields values of the form
        "RxCy" based on position.
   c_ndupe_l, r_ndupe_l - list of integers, determines the number
        of duplicates for each label at a given level of the corresponding
        index. The default `None` value produces a multiplicity of 1 across
        all levels, i.e. a unique index. Will accept a partial list of length
        N < idx_nlevels, for just the first N levels. If ndupe doesn't divide
        nrows/ncol, the last label might have lower multiplicity.
   dtype - passed to the DataFrame constructor as is, in case you wish to
        have more control in conjuncion with a custom `data_gen_f`
   r_idx_type, c_idx_type -  "i"/"f"/"s"/"u"/"dt"/"td".
       If idx_type is not None, `idx_nlevels` must be 1.
       "i"/"f" creates an integer/float index,
       "s"/"u" creates a string/unicode index
       "dt" create a datetime index.
       "td" create a timedelta index.

        if unspecified, string labels will be generated.

    Examples:

    # 5 row, 3 columns, default names on both, single index on both axis
    >> makeCustomDataframe(5,3)

    # make the data a random int between 1 and 100
    >> mkdf(5,3,data_gen_f=lambda r,c:randint(1,100))

    # 2-level multiindex on rows with each label duplicated
    # twice on first level, default names on both axis, single
    # index on both axis
    >> a=makeCustomDataframe(5,3,r_idx_nlevels=2,r_ndupe_l=[2])

    # DatetimeIndex on row, index with unicode labels on columns
    # no names on either axis
    >> a=makeCustomDataframe(5,3,c_idx_names=False,r_idx_names=False,
                             r_idx_type="dt",c_idx_type="u")

    # 4-level multindex on rows with names provided, 2-level multindex
    # on columns with default labels and default names.
    >> a=makeCustomDataframe(5,3,r_idx_nlevels=4,
                             r_idx_names=["FEE","FI","FO","FAM"],
                             c_idx_nlevels=2)

    >> a=mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
    """
    ...

def _create_missing_idx(nrows, ncols, density, random_state: Optional[Any] = ...):
    ...

def makeMissingCustomDataframe(nrows, ncols, density=..., random_state: Optional[Any] = ..., c_idx_names: bool = ..., r_idx_names: bool = ..., c_idx_nlevels=..., r_idx_nlevels=..., data_gen_f: Optional[Any] = ..., c_ndupe_l: Optional[Any] = ..., r_ndupe_l: Optional[Any] = ..., dtype: Optional[Any] = ..., c_idx_type: Optional[Any] = ..., r_idx_type: Optional[Any] = ...):
    """
    Parameters
    ----------
    Density : float, optional
        Float in (0, 1) that gives the percentage of non-missing numbers in
        the DataFrame.
    random_state : {np.random.RandomState, int}, optional
        Random number generator or random seed.

    See makeCustomDataframe for descriptions of the rest of the parameters.
    """
    ...

def makeMissingDataframe(density=..., random_state: Optional[Any] = ...):
    ...

def add_nans(panel):
    ...

def add_nans_panel4d(panel4d):
    ...

class TestSubDict(dict):
    def __init__(self, *args, **kwargs):
        ...
    


def skip_if_no_package(pkg_name, min_version: Optional[Any] = ..., max_version: Optional[Any] = ..., app=..., checker=...):
    """Check that the min/max version of the required package is installed.

    If the package check fails, the test is automatically skipped.

    Parameters
    ----------
    pkg_name : string
        Name of the required package.
    min_version : string, optional
        Minimal version number for required package.
    max_version : string, optional
        Max version number for required package.
    app : string, optional
        Application that is performing the check. For instance, the
        name of the tutorial being executed that depends on specific
        packages.
    checker : object, optional
        The class that will perform the version checking. Default is
        distutils.version.LooseVersion.

    Examples
    --------
    package_check('numpy', '1.3')

    """
    ...

def optional_args(decorator):
    """allows a decorator to take optional positional and keyword arguments.
    Assumes that taking a single, callable, positional argument means that
    it is decorating a function, i.e. something like this::

        @my_decorator
        def function(): pass

    Calls decorator with decorator(f, *args, **kwargs)"""
    ...

_network_error_messages = ('timed out', 'Server Hangup', 'HTTP Error 503: Service Unavailable', '502: Proxy Error', 'HTTP Error 502: internal error', 'HTTP Error 502', 'HTTP Error 503', 'HTTP Error 403', 'HTTP Error 400', 'Temporary failure in name resolution', 'Name or service not known', 'Connection refused', 'certificate verify')
_network_errno_vals = (101, 111, 110, 104, 54, 60)
_network_error_classes = (IOError, httplib.HTTPException)
if sys.version_info >= (3, 3):
    ...
def can_connect(url, error_classes=...):
    """Try to connect to the given url. True if succeeds, False if IOError
    raised

    Parameters
    ----------
    url : basestring
        The URL to try to connect to

    Returns
    -------
    connectable : bool
        Return True if no IOError (unable to connect) or URLError (bad url) was
        raised
    """
    ...

@optional_args
def network(t, url=..., raise_on_error: bool = ..., check_before_test: bool = ..., error_classes=..., skip_errnos=..., _skip_on_messages=...):
    """
    Label a test as requiring network connection and, if an error is
    encountered, only raise if it does not find a network connection.

    In comparison to ``network``, this assumes an added contract to your test:
    you must assert that, under normal conditions, your test will ONLY fail if
    it does not have network connectivity.

    You can call this in 3 ways: as a standard decorator, with keyword
    arguments, or with a positional argument that is the url to check.

    Parameters
    ----------
    t : callable
        The test requiring network connectivity.
    url : path
        The url to test via ``pandas.io.common.urlopen`` to check
        for connectivity. Defaults to 'http://www.google.com'.
    raise_on_error : bool
        If True, never catches errors.
    check_before_test : bool
        If True, checks connectivity before running the test case.
    error_classes : tuple or Exception
        error classes to ignore. If not in ``error_classes``, raises the error.
        defaults to IOError. Be careful about changing the error classes here.
    skip_errnos : iterable of int
        Any exception that has .errno or .reason.erno set to one
        of these values will be skipped with an appropriate
        message.
    _skip_on_messages: iterable of string
        any exception e for which one of the strings is
        a substring of str(e) will be skipped with an appropriate
        message. Intended to supress errors where an errno isn't available.

    Notes
    -----
    * ``raise_on_error`` supercedes ``check_before_test``

    Returns
    -------
    t : callable
        The decorated test ``t``, with checks for connectivity errors.

    Example
    -------

    Tests decorated with @network will fail if it's possible to make a network
    connection to another URL (defaults to google.com)::

      >>> from pandas.util.testing import network
      >>> from pandas.io.common import urlopen
      >>> @network
      ... def test_network():
      ...     with urlopen("rabbit://bonanza.com"):
      ...         pass
      Traceback
         ...
      URLError: <urlopen error unknown url type: rabit>

      You can specify alternative URLs::

        >>> @network("http://www.yahoo.com")
        ... def test_something_with_yahoo():
        ...    raise IOError("Failure Message")
        >>> test_something_with_yahoo()
        Traceback (most recent call last):
            ...
        IOError: Failure Message

    If you set check_before_test, it will check the url first and not run the
    test on failure::

        >>> @network("failing://url.blaher", check_before_test=True)
        ... def test_something():
        ...     print("I ran!")
        ...     raise ValueError("Failure")
        >>> test_something()
        Traceback (most recent call last):
            ...

    Errors not related to networking will always be raised.
    """
    ...

with_connectivity_check = network
class SimpleMock(object):
    """
    Poor man's mocking object

    Note: only works for new-style classes, assumes  __getattribute__ exists.

    >>> a = type("Duck",(),{})
    >>> a.attr1,a.attr2 ="fizz","buzz"
    >>> b = SimpleMock(a,"attr1","bar")
    >>> b.attr1 == "bar" and b.attr2 == "buzz"
    True
    >>> a.attr1 == "fizz" and a.attr2 == "buzz"
    True
    """
    def __init__(self, obj, *args, **kwds):
        self.attrs = ...
        self.obj = ...
    
    def __getattribute__(self, name):
        ...
    


@contextmanager
def stdin_encoding(encoding: Optional[Any] = ...):
    """
    Context manager for running bits of code while emulating an arbitrary
    stdin encoding.

    >>> import sys
    >>> _encoding = sys.stdin.encoding
    >>> with stdin_encoding('AES'): sys.stdin.encoding
    'AES'
    >>> sys.stdin.encoding==_encoding
    True

    """
    ...

def assert_raises_regex(_exception, _regexp, _callable: Optional[Any] = ..., *args, **kwargs):
    r"""
    Check that the specified Exception is raised and that the error message
    matches a given regular expression pattern. This may be a regular
    expression object or a string containing a regular expression suitable
    for use by `re.search()`. This is a port of the `assertRaisesRegexp`
    function from unittest in Python 2.7.

    Examples
    --------
    >>> assert_raises_regex(ValueError, 'invalid literal for.*XYZ', int, 'XYZ')
    >>> import re
    >>> assert_raises_regex(ValueError, re.compile('literal'), int, 'XYZ')

    If an exception of a different type is raised, it bubbles up.

    >>> assert_raises_regex(TypeError, 'literal', int, 'XYZ')
    Traceback (most recent call last):
        ...
    ValueError: invalid literal for int() with base 10: 'XYZ'
    >>> dct = dict()
    >>> assert_raises_regex(KeyError, 'pear', dct.__getitem__, 'apple')
    Traceback (most recent call last):
        ...
    AssertionError: "pear" does not match "'apple'"

    You can also use this in a with statement.
    >>> with assert_raises_regex(TypeError, 'unsupported operand type\(s\)'):
    ...     1 + {}
    >>> with assert_raises_regex(TypeError, 'banana'):
    ...     'apple'[0] = 'b'
    Traceback (most recent call last):
        ...
    AssertionError: "banana" does not match "'str' object does not support \
item assignment"
    """
    ...

class _AssertRaisesContextmanager(object):
    """
    Context manager behind `assert_raises_regex`.
    """
    def __init__(self, exception, regexp: Optional[Any] = ...):
        """
        Initialize an _AssertRaisesContextManager instance.

        Parameters
        ----------
        exception : class
            The expected Exception class.
        regexp : str, default None
            The regex to compare against the Exception message.
        """
        self.exception = ...
        self.regexp = ...
    
    def __enter__(self):
        ...
    
    def __exit__(self, exc_type, exc_value, trace_back):
        ...
    
    def exception_matches(self, exc_type, exc_value, trace_back):
        """
        Check that the Exception raised matches the expected Exception
        and expected error message regular expression.

        Parameters
        ----------
        exc_type : class
            The type of Exception raised.
        exc_value : Exception
            The instance of `exc_type` raised.
        trace_back : stack trace object
            The traceback object associated with `exc_value`.

        Returns
        -------
        is_matched : bool
            Whether or not the Exception raised matches the expected
            Exception class and expected error message regular expression.

        Raises
        ------
        AssertionError : The error message provided does not match
                         the expected error message regular expression.
        """
        ...
    


@contextmanager
def assert_produces_warning(expected_warning=..., filter_level=..., clear: Optional[Any] = ..., check_stacklevel: bool = ...):
    """
    Context manager for running code that expects to raise (or not raise)
    warnings.  Checks that code raises the expected warning and only the
    expected warning. Pass ``False`` or ``None`` to check that it does *not*
    raise a warning. Defaults to ``exception.Warning``, baseclass of all
    Warnings. (basically a wrapper around ``warnings.catch_warnings``).

    >>> import warnings
    >>> with assert_produces_warning():
    ...     warnings.warn(UserWarning())
    ...
    >>> with assert_produces_warning(False):
    ...     warnings.warn(RuntimeWarning())
    ...
    Traceback (most recent call last):
        ...
    AssertionError: Caused unexpected warning(s): ['RuntimeWarning'].
    >>> with assert_produces_warning(UserWarning):
    ...     warnings.warn(RuntimeWarning())
    Traceback (most recent call last):
        ...
    AssertionError: Did not see expected warning of class 'UserWarning'.

    ..warn:: This is *not* thread-safe.
    """
    ...

class RNGContext(object):
    """
    Context manager to set the numpy random number generator speed. Returns
    to the original value upon exiting the context manager.

    Parameters
    ----------
    seed : int
        Seed for numpy.random.seed

    Examples
    --------

    with RNGContext(42):
        np.random.randn()
    """
    def __init__(self, seed):
        self.seed = ...
    
    def __enter__(self):
        self.start_state = ...
    
    def __exit__(self, exc_type, exc_value, traceback):
        ...
    


@contextmanager
def use_numexpr(use, min_elements: Optional[Any] = ...):
    ...

def test_parallel(num_threads=..., kwargs_list: Optional[Any] = ...):
    """Decorator to run the same function multiple times in parallel.

    Parameters
    ----------
    num_threads : int, optional
        The number of times the function is run in parallel.
    kwargs_list : list of dicts, optional
        The list of kwargs to update original
        function kwargs on different threads.
    Notes
    -----
    This decorator does not pass the return value of the decorated function.

    Original from scikit-image:

    https://github.com/scikit-image/scikit-image/pull/1519

    """
    ...

class SubclassedSeries(Series):
    _metadata = ...
    @property
    def _constructor(self):
        ...
    
    @property
    def _constructor_expanddim(self):
        ...
    


class SubclassedDataFrame(DataFrame):
    _metadata = ...
    @property
    def _constructor(self):
        ...
    
    @property
    def _constructor_sliced(self):
        ...
    


class SubclassedSparseSeries(pd.SparseSeries):
    _metadata = ...
    @property
    def _constructor(self):
        ...
    
    @property
    def _constructor_expanddim(self):
        ...
    


class SubclassedSparseDataFrame(pd.SparseDataFrame):
    _metadata = ...
    @property
    def _constructor(self):
        ...
    
    @property
    def _constructor_sliced(self):
        ...
    


class SubclassedCategorical(Categorical):
    @property
    def _constructor(self):
        ...
    


@contextmanager
def patch(ob, attr, value):
    """Temporarily patch an attribute of an object.

    Parameters
    ----------
    ob : any
        The object to patch. This must support attribute assignment for `attr`.
    attr : str
        The name of the attribute to patch.
    value : any
        The temporary attribute to assign.

    Examples
    --------
    >>> class C(object):
    ...     attribute = 'original'
    ...
    >>> C.attribute
    'original'
    >>> with patch(C, 'attribute', 'patched'):
    ...     in_context = C.attribute
    ...
    >>> in_context
    'patched'
    >>> C.attribute  # the value is reset when the context manager exists
    'original'

    Correctly replaces attribute when the manager exits with an exception.
    >>> with patch(C, 'attribute', 'patched'):
    ...     in_context = C.attribute
    ...     raise ValueError()
    Traceback (most recent call last):
       ...
    ValueError
    >>> in_context
    'patched'
    >>> C.attribute
    'original'
    """
    ...

@contextmanager
def set_timezone(tz):
    """Context manager for temporarily setting a timezone.

    Parameters
    ----------
    tz : str
        A string representing a valid timezone.

    Examples
    --------

    >>> from datetime import datetime
    >>> from dateutil.tz import tzlocal
    >>> tzlocal().tzname(datetime.now())
    'IST'

    >>> with set_timezone('US/Eastern'):
    ...     tzlocal().tzname(datetime.now())
    ...
    'EDT'
    """
    ...

def _make_skipna_wrapper(alternative, skipna_alternative: Optional[Any] = ...):
    """Create a function for calling on an array.

    Parameters
    ----------
    alternative : function
        The function to be called on the array with no NaNs.
        Only used when 'skipna_alternative' is None.
    skipna_alternative : function
        The function to be called on the original array

    Returns
    -------
    skipna_wrapper : function
    """
    ...

