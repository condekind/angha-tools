{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/usr/bin/python3\n",
    "\n",
    "# standard libs\n",
    "import re, json, subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# custom modules\n",
    "from modules.benchinfo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "inputstr =                                              \\\n",
    "    '#include <stdlib.h>\\n'                             \\\n",
    "    '#include <stdio.h>\\n'                              \\\n",
    "    '\\n'                                                \\\n",
    "    'int main(int argc, char *argv[])\\n'                \\\n",
    "    '{\\n'                                               \\\n",
    "    '  int a, b = 0;\\n'                                 \\\n",
    "    '  print(\"Hello world!\\\\n\");\\n'                     \\\n",
    "    '}\\n'\n",
    "\n",
    "proc_result = subprocess.run('scripts/extract.sh',\n",
    "                                input=inputstr,\n",
    "                                capture_output=True,\n",
    "                                text=True)\n",
    "\n",
    "input_stats = parse_stats(proc_result.stderr)\n",
    "\n",
    "input_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawstats_dir = Path('data/raw-stats')\n",
    "delim = '\\nheader://:'\n",
    "DEBUG_LIMIT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_pattern = '^header://:(.*)://:(.*)://:(.*)://:endheader$'\n",
    "stats_pattern  = '^ *\\d+\\s+\\S+\\s+-\\s+.*$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - FIX THE ://: SPLIT\n",
    "# featureset = set()\n",
    "# for infile in rawstats_dir.iterdir():\n",
    "#     with infile.open() as stats_file:\n",
    "#         raw_benchmarks = [\n",
    "#             (h, d)\n",
    "#             for entry\n",
    "#             in list(stats_file)\n",
    "#             if (header(entry))\n",
    "#         ]\n",
    "#         [\n",
    "#             [featureset.add(f[1]) for f in parse_stats(_[3]) if len(f) >= 2]\n",
    "#             for _\n",
    "#             in [\n",
    "#                 raw_benchmark.split('://:')\n",
    "#                 for raw_benchmark\n",
    "#                 in raw_benchmarks\n",
    "#             ]\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "idx_tuples = []\n",
    "stats_list = []\n",
    "\n",
    "for infile in rawstats_dir.iterdir():\n",
    "    with infile.open() as stats_file:\n",
    "        raw_benchmarks = [\n",
    "            entry\n",
    "            for entry\n",
    "            in ''.join(list(stats_file)).split('header://:')[1:DEBUG_LIMIT]\n",
    "        ]\n",
    "        suite_rawstats = [\n",
    "            (suite, bench, files, data)\n",
    "            for suite, bench, files, data\n",
    "            in [\n",
    "                raw_benchmark.split('://:')\n",
    "                for raw_benchmark\n",
    "                in raw_benchmarks\n",
    "            ]\n",
    "        ]\n",
    "        for suite, bench, files, data in suite_rawstats:\n",
    "            idx_tuples.append( (suite, bench) )\n",
    "            suite_stats = parse_stats(data)\n",
    "            stats_list.append({k: v for k, v in suite_stats})\n",
    "            #pprint(suite_stats)list.appe\n",
    "            \n",
    "idx = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "pd.DataFrame()\n",
    "\n",
    "for i, s in zip(idx_tuples, stats_list):\n",
    "    #\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(idx_tuples, names=['suite', 'benchmark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):    \n",
    "    res = []  # Result list\n",
    "    if isinstance(d, dict):\n",
    "        for key, val in d.items():\n",
    "            res.extend(flatten(val))\n",
    "    elif isinstance(d, list):\n",
    "        res = d        \n",
    "    else:\n",
    "        raise TypeError(\"Undefined type for flatten: %s\"%type(d))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('cache/stats.pkl.bz2')\n",
    "df.index.names = ['suite', 'name']\n",
    "benchmarkContainer = {\n",
    "    'referenceFeatures': { k: 0 for k in BenchmarkFeatures },\n",
    "    'closestBenchs': [ <hr></hr>_ for _ in df.head(n) ],  # closest n in df (not implemented)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(24, 18))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=18, rotation=90)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=18)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=18)\n",
    "# plt.title('', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_features(dest, features):\n",
    "    for p, d, n in features:  # pass, description, number\n",
    "        if p in dest:\n",
    "            if d in dest[p]:\n",
    "                dest[p][d] += int(n)\n",
    "            else:\n",
    "                dest[p][d] = int(n)\n",
    "        else:\n",
    "            dest[p] = { d: int(n) }\n",
    "            \n",
    "def closest(*, program, df):\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bench():\n",
    "    return {\n",
    "        \"name\": random.choice(bNames),\n",
    "        \"suite\": random.choice(sNames),\n",
    "        \"content\": random.choice(bCode),\n",
    "        \"features\": {\n",
    "            random.choice(): n\n",
    "            for //\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export interface Benchmark {\n",
    "#  name: string\n",
    "#  suite: string\n",
    "#  content: string\n",
    "#  features: BenchmarkFeatures\n",
    "#}\n",
    "#\n",
    "#export interface BenchmarkContainer {\n",
    "#  referenceFeatures: BenchmarkFeatures,\n",
    "#  closestBenchs: Array<Benchmark>\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
